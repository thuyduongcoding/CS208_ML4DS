{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VngLX2Ev4Lq2",
        "S8LbCRiI-b1T",
        "cKgJjILwD6Bm",
        "dF56TkrOLFHo",
        "U4sq4Vg2OA7i",
        "WYz8EAzESIuV",
        "WTg6fYxdZMtF",
        "tjjQJi9W64Hz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5: Deep Learning {-}\n",
        "\n",
        "This assignment aims at familiarizing you with training and testing a Deep Neural Network (DNN). Here are the BASIC requirements of the assignment:\n",
        "\n",
        "- Load the data.\n",
        "- Process and normalize the images.\n",
        "- Build, train and test the two following Deep Neural Networks:\n",
        " - First network: must at least consist of three (03) Convolutional layers, two (02) Fully Connected layers, two (02) Pooling layers.\n",
        " - Second network: has at most 4M (four millions) parameters (use model.summary() to check). The architecture is of your choice.\n",
        "- Evaluate the model performance on the test set.\n",
        "\n",
        "The dataset you will be working on is cifar10 (https://www.cs.toronto.edu/~kriz/cifar.html) which consists of 60,000 32x32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. Here follows the ten object classes:\n",
        "* airplane\n",
        "*\tautomobile\n",
        "*\tbird\n",
        "*\tcat\n",
        "*\tdeer\n",
        "*\tdog\n",
        "*\tfrog\n",
        "*\thorse\n",
        "*\tship\n",
        "*\ttruck\n",
        "\n",
        "Here follows some data samples in the dataset:\n",
        "\n",
        "![alt text](https://storage.googleapis.com/kaggle-competitions/kaggle/3649/media/cifar-10.png)\n",
        "\n",
        "### Submission {-}\n",
        "The structure of submission folder should be organized as follows:\n",
        "\n",
        "- ./\\<StudentID>-assignment5-notebook.ipynb: Jupyter notebook containing source code.\n",
        "- ./\\<Test-accuracy>-\\<StudentID>.txt: accuracy of the second network on the test set (for extra credit, see the 'Evaluation' part below). For example if you get 0.8124 accuracy, the name of this file is 08124-2012345.txt. The file content is left empty.\n",
        "\n",
        "The submission folder is named ML4DS-\\<StudentID>-Assignment5 (e.g., ML4DS-2012345-Assigment5) and then compressed with the same name.\n",
        "    \n",
        "### Evaluation {-}\n",
        "Assignment evaluation will be conducted on how you accomplish the assignment requirements. It is a plus if you have modeling steps other than the basic requirements and achieve an excellent model accuracy. In addition, your code should conform to a Python coding convention such as PEP-8.\n",
        "\n",
        "EXTRA CREDIT: Top-3 submissions achieving the highest test accuracy on the second network (of 4M params at most) will be rewarded an extra credit. Please follow the submission format to be eligible for this extra credit.\n",
        "\n",
        "### Deadline {-}\n",
        "Please visit Canvas for details."
      ],
      "metadata": {
        "id": "rUB9PinqTxsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the libraries and data"
      ],
      "metadata": {
        "id": "Tz5z13xkT4R3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WZCEwNmL2pgL"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras              # Keras is the high-level API of TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Conv2D, Dense, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "TTktboHj3wzI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PLEASE DO NOT CHANGE THIS CODE\n",
        "\n",
        "# Load the cifar10 dataset and split train/test\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Split train/valid from the training set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=5)\n",
        "\n",
        "print(\"Train shape: X_train = \" + str(X_train.shape) + \", y_train = \" + str(y_train.shape))\n",
        "print(\"Validation shape: X_val = \" + str(X_val.shape) + \", y_val = \" + str(y_val.shape))\n",
        "print(\"Test shape: X_test = \" + str(X_test.shape) + \", y_test = \" + str(y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjrg5L6j3p4I",
        "outputId": "35b636a8-7cda-4811-a9cb-4828e7ee5167"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "Train shape: X_train = (45000, 32, 32, 3), y_train = (45000, 1)\n",
            "Validation shape: X_val = (5000, 32, 32, 3), y_val = (5000, 1)\n",
            "Test shape: X_test = (10000, 32, 32, 3), y_test = (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process and normalize images"
      ],
      "metadata": {
        "id": "RUTAKix8T8t_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values\n",
        "X_train_norm, X_val_norm, X_test_norm = X_train/255.0, X_val/255.0, X_test/255.0\n",
        "\n",
        "# One-hot-encoding labels\n",
        "y_train, y_val, y_test = to_categorical(y_train), to_categorical(y_val), to_categorical(y_test)"
      ],
      "metadata": {
        "id": "UIcT7dgU4HxD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First Network"
      ],
      "metadata": {
        "id": "WYz8EAzESIuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=X_train_norm[0].shape)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_6 = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCLkJxDvSISF",
        "outputId": "b3426473-fd3e-46b1-ed03-13f99b97661a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_26 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_196 (Conv2D)         (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_187 (Ba  (None, 32, 32, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_197 (Conv2D)         (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_188 (Ba  (None, 32, 32, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_83 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_122 (Dropout)       (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_198 (Conv2D)         (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_189 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_199 (Conv2D)         (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_190 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_84 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_123 (Dropout)       (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_200 (Conv2D)         (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_191 (Ba  (None, 8, 8, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_201 (Conv2D)         (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_192 (Ba  (None, 8, 8, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_85 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_124 (Dropout)       (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_202 (Conv2D)         (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_193 (Ba  (None, 4, 4, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_203 (Conv2D)         (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_194 (Ba  (None, 4, 4, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_86 (MaxPoolin  (None, 2, 2, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_125 (Dropout)       (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten_17 (Flatten)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_126 (Dropout)       (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_127 (Dropout)       (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,235,946\n",
            "Trainable params: 2,234,026\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_6.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, # Define loss function\n",
        "                optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy']) # Define initial learning rate and metrics.\n",
        "\n",
        "# Train the model. Using Colab for training\n",
        "history_6 = model_6.fit(X_train_norm, y_train, # Data feature and data label\n",
        "                    batch_size=1024, # Batch size\n",
        "                    epochs=200, # Number of training epochs\n",
        "                    validation_data=(X_val_norm, y_val)) # Validation set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecjf-9dBSZ1U",
        "outputId": "f1c8b012-e2cc-4cf3-c6bd-ccca62c7b482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "44/44 [==============================] - 7s 132ms/step - loss: 2.6084 - accuracy: 0.2632 - val_loss: 2.6524 - val_accuracy: 0.0960\n",
            "Epoch 2/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 1.5936 - accuracy: 0.4099 - val_loss: 3.5880 - val_accuracy: 0.0960\n",
            "Epoch 3/200\n",
            "44/44 [==============================] - 6s 127ms/step - loss: 1.4151 - accuracy: 0.4795 - val_loss: 3.9778 - val_accuracy: 0.0960\n",
            "Epoch 4/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 1.2563 - accuracy: 0.5457 - val_loss: 3.6856 - val_accuracy: 0.1106\n",
            "Epoch 5/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 1.1333 - accuracy: 0.5934 - val_loss: 3.4078 - val_accuracy: 0.1142\n",
            "Epoch 6/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 1.0352 - accuracy: 0.6301 - val_loss: 3.1019 - val_accuracy: 0.1828\n",
            "Epoch 7/200\n",
            "44/44 [==============================] - 6s 129ms/step - loss: 0.9599 - accuracy: 0.6594 - val_loss: 2.7794 - val_accuracy: 0.2426\n",
            "Epoch 8/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.8935 - accuracy: 0.6879 - val_loss: 2.5596 - val_accuracy: 0.3272\n",
            "Epoch 9/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.8296 - accuracy: 0.7052 - val_loss: 2.5291 - val_accuracy: 0.3398\n",
            "Epoch 10/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.7805 - accuracy: 0.7267 - val_loss: 1.6012 - val_accuracy: 0.4804\n",
            "Epoch 11/200\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.7394 - accuracy: 0.7424 - val_loss: 1.2434 - val_accuracy: 0.5874\n",
            "Epoch 12/200\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.6954 - accuracy: 0.7561 - val_loss: 1.1329 - val_accuracy: 0.6206\n",
            "Epoch 13/200\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.6632 - accuracy: 0.7682 - val_loss: 0.9629 - val_accuracy: 0.6658\n",
            "Epoch 14/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.6333 - accuracy: 0.7774 - val_loss: 0.7841 - val_accuracy: 0.7254\n",
            "Epoch 15/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.6042 - accuracy: 0.7893 - val_loss: 0.7393 - val_accuracy: 0.7472\n",
            "Epoch 16/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.5844 - accuracy: 0.7967 - val_loss: 0.7174 - val_accuracy: 0.7516\n",
            "Epoch 17/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.5532 - accuracy: 0.8069 - val_loss: 0.6943 - val_accuracy: 0.7606\n",
            "Epoch 18/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.5339 - accuracy: 0.8135 - val_loss: 0.8701 - val_accuracy: 0.7144\n",
            "Epoch 19/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.5098 - accuracy: 0.8222 - val_loss: 0.6600 - val_accuracy: 0.7756\n",
            "Epoch 20/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.4845 - accuracy: 0.8316 - val_loss: 0.6121 - val_accuracy: 0.7886\n",
            "Epoch 21/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.4687 - accuracy: 0.8372 - val_loss: 0.5711 - val_accuracy: 0.8060\n",
            "Epoch 22/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.4464 - accuracy: 0.8421 - val_loss: 0.5573 - val_accuracy: 0.8130\n",
            "Epoch 23/200\n",
            "44/44 [==============================] - 6s 128ms/step - loss: 0.4319 - accuracy: 0.8505 - val_loss: 0.5977 - val_accuracy: 0.7906\n",
            "Epoch 24/200\n",
            "44/44 [==============================] - 6s 128ms/step - loss: 0.4130 - accuracy: 0.8564 - val_loss: 0.5878 - val_accuracy: 0.8042\n",
            "Epoch 25/200\n",
            "44/44 [==============================] - 6s 132ms/step - loss: 0.3920 - accuracy: 0.8634 - val_loss: 0.7677 - val_accuracy: 0.7642\n",
            "Epoch 26/200\n",
            "44/44 [==============================] - 6s 133ms/step - loss: 0.3979 - accuracy: 0.8609 - val_loss: 0.5532 - val_accuracy: 0.8144\n",
            "Epoch 27/200\n",
            "44/44 [==============================] - 6s 129ms/step - loss: 0.3760 - accuracy: 0.8682 - val_loss: 0.5618 - val_accuracy: 0.8148\n",
            "Epoch 28/200\n",
            "44/44 [==============================] - 6s 129ms/step - loss: 0.3580 - accuracy: 0.8747 - val_loss: 0.6191 - val_accuracy: 0.8060\n",
            "Epoch 29/200\n",
            "44/44 [==============================] - 6s 129ms/step - loss: 0.3489 - accuracy: 0.8773 - val_loss: 0.5321 - val_accuracy: 0.8196\n",
            "Epoch 30/200\n",
            "44/44 [==============================] - 6s 128ms/step - loss: 0.3352 - accuracy: 0.8826 - val_loss: 0.5758 - val_accuracy: 0.8168\n",
            "Epoch 31/200\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.3269 - accuracy: 0.8848 - val_loss: 0.5943 - val_accuracy: 0.8070\n",
            "Epoch 32/200\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.3122 - accuracy: 0.8896 - val_loss: 0.5687 - val_accuracy: 0.8212\n",
            "Epoch 33/200\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.3105 - accuracy: 0.8914 - val_loss: 0.5457 - val_accuracy: 0.8308\n",
            "Epoch 34/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.2921 - accuracy: 0.8964 - val_loss: 0.5445 - val_accuracy: 0.8296\n",
            "Epoch 35/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.2844 - accuracy: 0.8995 - val_loss: 0.5679 - val_accuracy: 0.8274\n",
            "Epoch 36/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.2764 - accuracy: 0.9031 - val_loss: 0.5543 - val_accuracy: 0.8278\n",
            "Epoch 37/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.2687 - accuracy: 0.9050 - val_loss: 0.5562 - val_accuracy: 0.8312\n",
            "Epoch 38/200\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.2595 - accuracy: 0.9085 - val_loss: 0.5309 - val_accuracy: 0.8386\n",
            "Epoch 39/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.2561 - accuracy: 0.9093 - val_loss: 0.5647 - val_accuracy: 0.8332\n",
            "Epoch 40/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.2439 - accuracy: 0.9135 - val_loss: 0.5705 - val_accuracy: 0.8308\n",
            "Epoch 41/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.2397 - accuracy: 0.9153 - val_loss: 0.5249 - val_accuracy: 0.8368\n",
            "Epoch 42/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.2307 - accuracy: 0.9190 - val_loss: 0.5562 - val_accuracy: 0.8386\n",
            "Epoch 43/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.2258 - accuracy: 0.9184 - val_loss: 0.5720 - val_accuracy: 0.8374\n",
            "Epoch 44/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.2158 - accuracy: 0.9230 - val_loss: 0.5626 - val_accuracy: 0.8388\n",
            "Epoch 45/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.2156 - accuracy: 0.9231 - val_loss: 0.5899 - val_accuracy: 0.8316\n",
            "Epoch 46/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.2095 - accuracy: 0.9247 - val_loss: 0.5591 - val_accuracy: 0.8394\n",
            "Epoch 47/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.2059 - accuracy: 0.9259 - val_loss: 0.5515 - val_accuracy: 0.8400\n",
            "Epoch 48/200\n",
            "44/44 [==============================] - 5s 124ms/step - loss: 0.1988 - accuracy: 0.9290 - val_loss: 0.6168 - val_accuracy: 0.8304\n",
            "Epoch 49/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1988 - accuracy: 0.9288 - val_loss: 0.5448 - val_accuracy: 0.8414\n",
            "Epoch 50/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1885 - accuracy: 0.9324 - val_loss: 0.5780 - val_accuracy: 0.8344\n",
            "Epoch 51/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1786 - accuracy: 0.9366 - val_loss: 0.5741 - val_accuracy: 0.8434\n",
            "Epoch 52/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1828 - accuracy: 0.9355 - val_loss: 0.6061 - val_accuracy: 0.8310\n",
            "Epoch 53/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1749 - accuracy: 0.9387 - val_loss: 0.5859 - val_accuracy: 0.8408\n",
            "Epoch 54/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1734 - accuracy: 0.9386 - val_loss: 0.5776 - val_accuracy: 0.8402\n",
            "Epoch 55/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1717 - accuracy: 0.9379 - val_loss: 0.6452 - val_accuracy: 0.8236\n",
            "Epoch 56/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.1691 - accuracy: 0.9402 - val_loss: 0.5605 - val_accuracy: 0.8428\n",
            "Epoch 57/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1610 - accuracy: 0.9428 - val_loss: 0.5594 - val_accuracy: 0.8472\n",
            "Epoch 58/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1571 - accuracy: 0.9435 - val_loss: 0.5555 - val_accuracy: 0.8522\n",
            "Epoch 59/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1580 - accuracy: 0.9432 - val_loss: 0.5515 - val_accuracy: 0.8478\n",
            "Epoch 60/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1481 - accuracy: 0.9477 - val_loss: 0.6198 - val_accuracy: 0.8350\n",
            "Epoch 61/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1516 - accuracy: 0.9469 - val_loss: 0.6219 - val_accuracy: 0.8400\n",
            "Epoch 62/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1522 - accuracy: 0.9452 - val_loss: 0.5800 - val_accuracy: 0.8436\n",
            "Epoch 63/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1478 - accuracy: 0.9477 - val_loss: 0.6676 - val_accuracy: 0.8302\n",
            "Epoch 64/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.1468 - accuracy: 0.9482 - val_loss: 0.6710 - val_accuracy: 0.8324\n",
            "Epoch 65/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1518 - accuracy: 0.9461 - val_loss: 0.6285 - val_accuracy: 0.8370\n",
            "Epoch 66/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1470 - accuracy: 0.9467 - val_loss: 0.5942 - val_accuracy: 0.8374\n",
            "Epoch 67/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1376 - accuracy: 0.9508 - val_loss: 0.5570 - val_accuracy: 0.8552\n",
            "Epoch 68/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1305 - accuracy: 0.9534 - val_loss: 0.5875 - val_accuracy: 0.8474\n",
            "Epoch 69/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1250 - accuracy: 0.9560 - val_loss: 0.5890 - val_accuracy: 0.8524\n",
            "Epoch 70/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1289 - accuracy: 0.9535 - val_loss: 0.6210 - val_accuracy: 0.8470\n",
            "Epoch 71/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1234 - accuracy: 0.9571 - val_loss: 0.5842 - val_accuracy: 0.8570\n",
            "Epoch 72/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1195 - accuracy: 0.9573 - val_loss: 0.6460 - val_accuracy: 0.8354\n",
            "Epoch 73/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1185 - accuracy: 0.9582 - val_loss: 0.5867 - val_accuracy: 0.8600\n",
            "Epoch 74/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1164 - accuracy: 0.9589 - val_loss: 0.6293 - val_accuracy: 0.8456\n",
            "Epoch 75/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1172 - accuracy: 0.9575 - val_loss: 0.5935 - val_accuracy: 0.8534\n",
            "Epoch 76/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1181 - accuracy: 0.9587 - val_loss: 0.5845 - val_accuracy: 0.8582\n",
            "Epoch 77/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1117 - accuracy: 0.9593 - val_loss: 0.5953 - val_accuracy: 0.8456\n",
            "Epoch 78/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1145 - accuracy: 0.9596 - val_loss: 0.5818 - val_accuracy: 0.8538\n",
            "Epoch 79/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1141 - accuracy: 0.9602 - val_loss: 0.5724 - val_accuracy: 0.8518\n",
            "Epoch 80/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1050 - accuracy: 0.9630 - val_loss: 0.5878 - val_accuracy: 0.8544\n",
            "Epoch 81/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1082 - accuracy: 0.9614 - val_loss: 0.6422 - val_accuracy: 0.8468\n",
            "Epoch 82/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1146 - accuracy: 0.9598 - val_loss: 0.5872 - val_accuracy: 0.8532\n",
            "Epoch 83/200\n",
            "44/44 [==============================] - 6s 127ms/step - loss: 0.1065 - accuracy: 0.9631 - val_loss: 0.5783 - val_accuracy: 0.8554\n",
            "Epoch 84/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1026 - accuracy: 0.9646 - val_loss: 0.6428 - val_accuracy: 0.8490\n",
            "Epoch 85/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1191 - accuracy: 0.9579 - val_loss: 0.6195 - val_accuracy: 0.8470\n",
            "Epoch 86/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1015 - accuracy: 0.9647 - val_loss: 0.6092 - val_accuracy: 0.8530\n",
            "Epoch 87/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1038 - accuracy: 0.9634 - val_loss: 0.5714 - val_accuracy: 0.8570\n",
            "Epoch 88/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1024 - accuracy: 0.9636 - val_loss: 0.6044 - val_accuracy: 0.8496\n",
            "Epoch 89/200\n",
            "44/44 [==============================] - 6s 127ms/step - loss: 0.0942 - accuracy: 0.9662 - val_loss: 0.5839 - val_accuracy: 0.8560\n",
            "Epoch 90/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0961 - accuracy: 0.9666 - val_loss: 0.5934 - val_accuracy: 0.8554\n",
            "Epoch 91/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0978 - accuracy: 0.9653 - val_loss: 0.5728 - val_accuracy: 0.8580\n",
            "Epoch 92/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0927 - accuracy: 0.9662 - val_loss: 0.6156 - val_accuracy: 0.8436\n",
            "Epoch 93/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0921 - accuracy: 0.9681 - val_loss: 0.6039 - val_accuracy: 0.8514\n",
            "Epoch 94/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0917 - accuracy: 0.9674 - val_loss: 0.6218 - val_accuracy: 0.8510\n",
            "Epoch 95/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0861 - accuracy: 0.9698 - val_loss: 0.6410 - val_accuracy: 0.8546\n",
            "Epoch 96/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0933 - accuracy: 0.9672 - val_loss: 0.6360 - val_accuracy: 0.8506\n",
            "Epoch 97/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0918 - accuracy: 0.9678 - val_loss: 0.6703 - val_accuracy: 0.8418\n",
            "Epoch 98/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0909 - accuracy: 0.9670 - val_loss: 0.6113 - val_accuracy: 0.8562\n",
            "Epoch 99/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0896 - accuracy: 0.9685 - val_loss: 0.6176 - val_accuracy: 0.8568\n",
            "Epoch 100/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0866 - accuracy: 0.9702 - val_loss: 0.6613 - val_accuracy: 0.8476\n",
            "Epoch 101/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0822 - accuracy: 0.9716 - val_loss: 0.6078 - val_accuracy: 0.8542\n",
            "Epoch 102/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0840 - accuracy: 0.9705 - val_loss: 0.6569 - val_accuracy: 0.8534\n",
            "Epoch 103/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0916 - accuracy: 0.9694 - val_loss: 0.5924 - val_accuracy: 0.8556\n",
            "Epoch 104/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1062 - accuracy: 0.9639 - val_loss: 0.5787 - val_accuracy: 0.8546\n",
            "Epoch 105/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0967 - accuracy: 0.9661 - val_loss: 0.6005 - val_accuracy: 0.8628\n",
            "Epoch 106/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0870 - accuracy: 0.9696 - val_loss: 0.6945 - val_accuracy: 0.8392\n",
            "Epoch 107/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0814 - accuracy: 0.9711 - val_loss: 0.6042 - val_accuracy: 0.8586\n",
            "Epoch 108/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0788 - accuracy: 0.9714 - val_loss: 0.6148 - val_accuracy: 0.8604\n",
            "Epoch 109/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0773 - accuracy: 0.9731 - val_loss: 0.6190 - val_accuracy: 0.8548\n",
            "Epoch 110/200\n",
            "44/44 [==============================] - 6s 127ms/step - loss: 0.0800 - accuracy: 0.9717 - val_loss: 0.5999 - val_accuracy: 0.8546\n",
            "Epoch 111/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0792 - accuracy: 0.9732 - val_loss: 0.6184 - val_accuracy: 0.8598\n",
            "Epoch 112/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0780 - accuracy: 0.9727 - val_loss: 0.6345 - val_accuracy: 0.8484\n",
            "Epoch 113/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0768 - accuracy: 0.9728 - val_loss: 0.6072 - val_accuracy: 0.8602\n",
            "Epoch 114/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0730 - accuracy: 0.9733 - val_loss: 0.6295 - val_accuracy: 0.8614\n",
            "Epoch 115/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0787 - accuracy: 0.9726 - val_loss: 0.6054 - val_accuracy: 0.8632\n",
            "Epoch 116/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0782 - accuracy: 0.9722 - val_loss: 0.6514 - val_accuracy: 0.8556\n",
            "Epoch 117/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0735 - accuracy: 0.9739 - val_loss: 0.6737 - val_accuracy: 0.8510\n",
            "Epoch 118/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0759 - accuracy: 0.9730 - val_loss: 0.6531 - val_accuracy: 0.8550\n",
            "Epoch 119/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0742 - accuracy: 0.9738 - val_loss: 0.5837 - val_accuracy: 0.8618\n",
            "Epoch 120/200\n",
            "44/44 [==============================] - 6s 128ms/step - loss: 0.0718 - accuracy: 0.9747 - val_loss: 0.6207 - val_accuracy: 0.8620\n",
            "Epoch 121/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0744 - accuracy: 0.9740 - val_loss: 0.5896 - val_accuracy: 0.8662\n",
            "Epoch 122/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0695 - accuracy: 0.9753 - val_loss: 0.6101 - val_accuracy: 0.8632\n",
            "Epoch 123/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0729 - accuracy: 0.9747 - val_loss: 0.6723 - val_accuracy: 0.8490\n",
            "Epoch 124/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0724 - accuracy: 0.9740 - val_loss: 0.6303 - val_accuracy: 0.8566\n",
            "Epoch 125/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0681 - accuracy: 0.9770 - val_loss: 0.6351 - val_accuracy: 0.8564\n",
            "Epoch 126/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0670 - accuracy: 0.9759 - val_loss: 0.6631 - val_accuracy: 0.8578\n",
            "Epoch 127/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0703 - accuracy: 0.9765 - val_loss: 0.6683 - val_accuracy: 0.8588\n",
            "Epoch 128/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0980 - accuracy: 0.9689 - val_loss: 0.6662 - val_accuracy: 0.8448\n",
            "Epoch 129/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0815 - accuracy: 0.9708 - val_loss: 0.6280 - val_accuracy: 0.8560\n",
            "Epoch 130/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0748 - accuracy: 0.9731 - val_loss: 0.6461 - val_accuracy: 0.8516\n",
            "Epoch 131/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0713 - accuracy: 0.9759 - val_loss: 0.6388 - val_accuracy: 0.8602\n",
            "Epoch 132/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0682 - accuracy: 0.9765 - val_loss: 0.6952 - val_accuracy: 0.8506\n",
            "Epoch 133/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0628 - accuracy: 0.9776 - val_loss: 0.6272 - val_accuracy: 0.8594\n",
            "Epoch 134/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0671 - accuracy: 0.9768 - val_loss: 0.6632 - val_accuracy: 0.8524\n",
            "Epoch 135/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0697 - accuracy: 0.9760 - val_loss: 0.7341 - val_accuracy: 0.8414\n",
            "Epoch 136/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0899 - accuracy: 0.9705 - val_loss: 0.5911 - val_accuracy: 0.8634\n",
            "Epoch 137/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0780 - accuracy: 0.9734 - val_loss: 0.6325 - val_accuracy: 0.8540\n",
            "Epoch 138/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0698 - accuracy: 0.9750 - val_loss: 0.6046 - val_accuracy: 0.8656\n",
            "Epoch 139/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0669 - accuracy: 0.9765 - val_loss: 0.6036 - val_accuracy: 0.8654\n",
            "Epoch 140/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0727 - accuracy: 0.9756 - val_loss: 0.6678 - val_accuracy: 0.8556\n",
            "Epoch 141/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0765 - accuracy: 0.9737 - val_loss: 0.6751 - val_accuracy: 0.8480\n",
            "Epoch 142/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0695 - accuracy: 0.9758 - val_loss: 0.6042 - val_accuracy: 0.8662\n",
            "Epoch 143/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0657 - accuracy: 0.9758 - val_loss: 0.6070 - val_accuracy: 0.8640\n",
            "Epoch 144/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0645 - accuracy: 0.9778 - val_loss: 0.6273 - val_accuracy: 0.8608\n",
            "Epoch 145/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0659 - accuracy: 0.9777 - val_loss: 0.6742 - val_accuracy: 0.8536\n",
            "Epoch 146/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0595 - accuracy: 0.9801 - val_loss: 0.6308 - val_accuracy: 0.8618\n",
            "Epoch 147/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0622 - accuracy: 0.9786 - val_loss: 0.6020 - val_accuracy: 0.8632\n",
            "Epoch 148/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0587 - accuracy: 0.9798 - val_loss: 0.6156 - val_accuracy: 0.8638\n",
            "Epoch 149/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0605 - accuracy: 0.9788 - val_loss: 0.6683 - val_accuracy: 0.8578\n",
            "Epoch 150/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0603 - accuracy: 0.9792 - val_loss: 0.6164 - val_accuracy: 0.8612\n",
            "Epoch 151/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 0.6464 - val_accuracy: 0.8618\n",
            "Epoch 152/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0604 - accuracy: 0.9791 - val_loss: 0.6886 - val_accuracy: 0.8538\n",
            "Epoch 153/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0612 - accuracy: 0.9790 - val_loss: 0.5985 - val_accuracy: 0.8660\n",
            "Epoch 154/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0582 - accuracy: 0.9796 - val_loss: 0.6418 - val_accuracy: 0.8598\n",
            "Epoch 155/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0583 - accuracy: 0.9804 - val_loss: 0.6548 - val_accuracy: 0.8604\n",
            "Epoch 156/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0643 - accuracy: 0.9785 - val_loss: 0.6572 - val_accuracy: 0.8592\n",
            "Epoch 157/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0660 - accuracy: 0.9768 - val_loss: 0.6365 - val_accuracy: 0.8630\n",
            "Epoch 158/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0584 - accuracy: 0.9794 - val_loss: 0.6392 - val_accuracy: 0.8606\n",
            "Epoch 159/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0577 - accuracy: 0.9801 - val_loss: 0.5971 - val_accuracy: 0.8680\n",
            "Epoch 160/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 0.5839 - val_accuracy: 0.8692\n",
            "Epoch 161/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0561 - accuracy: 0.9810 - val_loss: 0.6271 - val_accuracy: 0.8656\n",
            "Epoch 162/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0571 - accuracy: 0.9798 - val_loss: 0.6482 - val_accuracy: 0.8576\n",
            "Epoch 163/200\n",
            "44/44 [==============================] - 6s 129ms/step - loss: 0.0572 - accuracy: 0.9803 - val_loss: 0.6250 - val_accuracy: 0.8654\n",
            "Epoch 164/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.6260 - val_accuracy: 0.8642\n",
            "Epoch 165/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0538 - accuracy: 0.9812 - val_loss: 0.6755 - val_accuracy: 0.8646\n",
            "Epoch 166/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0532 - accuracy: 0.9821 - val_loss: 0.6355 - val_accuracy: 0.8658\n",
            "Epoch 167/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0529 - accuracy: 0.9814 - val_loss: 0.6639 - val_accuracy: 0.8606\n",
            "Epoch 168/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0511 - accuracy: 0.9814 - val_loss: 0.6731 - val_accuracy: 0.8636\n",
            "Epoch 169/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0515 - accuracy: 0.9819 - val_loss: 0.7331 - val_accuracy: 0.8552\n",
            "Epoch 170/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0603 - accuracy: 0.9792 - val_loss: 0.6567 - val_accuracy: 0.8648\n",
            "Epoch 171/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 0.7029 - val_accuracy: 0.8518\n",
            "Epoch 172/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0517 - accuracy: 0.9823 - val_loss: 0.6493 - val_accuracy: 0.8636\n",
            "Epoch 173/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0542 - accuracy: 0.9808 - val_loss: 0.6397 - val_accuracy: 0.8626\n",
            "Epoch 174/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0549 - accuracy: 0.9811 - val_loss: 0.6118 - val_accuracy: 0.8682\n",
            "Epoch 175/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0483 - accuracy: 0.9833 - val_loss: 0.7250 - val_accuracy: 0.8544\n",
            "Epoch 176/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0501 - accuracy: 0.9823 - val_loss: 0.6751 - val_accuracy: 0.8578\n",
            "Epoch 177/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.6977 - val_accuracy: 0.8592\n",
            "Epoch 178/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.1287 - accuracy: 0.9651 - val_loss: 0.9580 - val_accuracy: 0.8262\n",
            "Epoch 179/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.1108 - accuracy: 0.9638 - val_loss: 0.5651 - val_accuracy: 0.8584\n",
            "Epoch 180/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0672 - accuracy: 0.9767 - val_loss: 0.6583 - val_accuracy: 0.8530\n",
            "Epoch 181/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0702 - accuracy: 0.9773 - val_loss: 0.6315 - val_accuracy: 0.8626\n",
            "Epoch 182/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0654 - accuracy: 0.9777 - val_loss: 0.6111 - val_accuracy: 0.8628\n",
            "Epoch 183/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0599 - accuracy: 0.9788 - val_loss: 0.6309 - val_accuracy: 0.8612\n",
            "Epoch 184/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0541 - accuracy: 0.9819 - val_loss: 0.6420 - val_accuracy: 0.8586\n",
            "Epoch 185/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.6314 - val_accuracy: 0.8636\n",
            "Epoch 186/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.6756 - val_accuracy: 0.8558\n",
            "Epoch 187/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0537 - accuracy: 0.9814 - val_loss: 0.6455 - val_accuracy: 0.8652\n",
            "Epoch 188/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0523 - accuracy: 0.9826 - val_loss: 0.6344 - val_accuracy: 0.8592\n",
            "Epoch 189/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0461 - accuracy: 0.9834 - val_loss: 0.6794 - val_accuracy: 0.8620\n",
            "Epoch 190/200\n",
            "44/44 [==============================] - 6s 129ms/step - loss: 0.0515 - accuracy: 0.9823 - val_loss: 0.6689 - val_accuracy: 0.8608\n",
            "Epoch 191/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0510 - accuracy: 0.9827 - val_loss: 0.6178 - val_accuracy: 0.8682\n",
            "Epoch 192/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0488 - accuracy: 0.9839 - val_loss: 0.6991 - val_accuracy: 0.8500\n",
            "Epoch 193/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0457 - accuracy: 0.9840 - val_loss: 0.6402 - val_accuracy: 0.8646\n",
            "Epoch 194/200\n",
            "44/44 [==============================] - 6s 126ms/step - loss: 0.0489 - accuracy: 0.9841 - val_loss: 0.6532 - val_accuracy: 0.8686\n",
            "Epoch 195/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0501 - accuracy: 0.9831 - val_loss: 0.6475 - val_accuracy: 0.8612\n",
            "Epoch 196/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0488 - accuracy: 0.9830 - val_loss: 0.6069 - val_accuracy: 0.8662\n",
            "Epoch 197/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0481 - accuracy: 0.9843 - val_loss: 0.6843 - val_accuracy: 0.8600\n",
            "Epoch 198/200\n",
            "44/44 [==============================] - 5s 125ms/step - loss: 0.0466 - accuracy: 0.9844 - val_loss: 0.7719 - val_accuracy: 0.8482\n",
            "Epoch 199/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0436 - accuracy: 0.9850 - val_loss: 0.6474 - val_accuracy: 0.8678\n",
            "Epoch 200/200\n",
            "44/44 [==============================] - 6s 125ms/step - loss: 0.0468 - accuracy: 0.9837 - val_loss: 0.6354 - val_accuracy: 0.8662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training and validation performance\n",
        "f,ax=plt.subplots(2,1) \n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[0].plot(history_6.history['loss'], color='b',label='Training Loss')\n",
        "ax[0].plot(history_6.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[1].plot(history_6.history['accuracy'],color='b',label='Training Accuracy')\n",
        "ax[1].plot(history_6.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Z7HUEjinY3Uh",
        "outputId": "f0d6b4ff-b8e3-47e1-c262-ab1fad094624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f725b0aafa0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc_6 = model_6.evaluate(X_test_norm, y_test, verbose = 0)\n",
        "acc_6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a63FgPwlTE-H",
        "outputId": "71f5b01d-bb1c-4ec9-c141-23ef1650d1ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8683000206947327"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.save('model_6.h5')"
      ],
      "metadata": {
        "id": "hUZi1JSvTIP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second network"
      ],
      "metadata": {
        "id": "Gz5s79PAsKuI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model architecture"
      ],
      "metadata": {
        "id": "Kydumzg3gpg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=X_train_norm[0].shape)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_9 = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model_9.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xa0cNGEfxeC",
        "outputId": "1a0c07ac-f739-4731-9e93-d7adbcb03849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_56 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_56 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_57 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_57 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_28 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_58 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_58 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_59 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_59 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_60 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_61 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_62 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_63 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 2, 2, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,285,546\n",
            "Trainable params: 3,283,626\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_9.compile(loss = tf.keras.losses.categorical_crossentropy, # Define loss function\n",
        "                optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy']) # Define initial learning rate and metrics."
      ],
      "metadata": {
        "id": "ScBkZzDWlcU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "1MFW8gdFgYcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create data generator\n",
        "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)"
      ],
      "metadata": {
        "id": "iiufw9OhlYWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare iterator\n",
        "it_train = datagen.flow(X_train_norm, y_train, batch_size=64)"
      ],
      "metadata": {
        "id": "QNZ0qUjVlWfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training model"
      ],
      "metadata": {
        "id": "5WHSz42xgbIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "steps = int(X_train_norm.shape[0] / 64)\n",
        "history_9 = model_9.fit(it_train, steps_per_epoch=steps, epochs=200,validation_data=(X_val_norm, y_val), verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Fdmq_i1lUSY",
        "outputId": "396b387b-5697-4f52-9809-6b2d12ca3995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "703/703 [==============================] - 25s 34ms/step - loss: 1.6727 - accuracy: 0.3974 - val_loss: 1.5002 - val_accuracy: 0.4852\n",
            "Epoch 2/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.2279 - accuracy: 0.5634 - val_loss: 1.1912 - val_accuracy: 0.5926\n",
            "Epoch 3/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 1.0349 - accuracy: 0.6398 - val_loss: 1.1474 - val_accuracy: 0.6176\n",
            "Epoch 4/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.9186 - accuracy: 0.6868 - val_loss: 0.8103 - val_accuracy: 0.7134\n",
            "Epoch 5/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.8407 - accuracy: 0.7126 - val_loss: 1.0267 - val_accuracy: 0.6606\n",
            "Epoch 6/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7876 - accuracy: 0.7316 - val_loss: 0.9004 - val_accuracy: 0.7068\n",
            "Epoch 7/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.7400 - accuracy: 0.7513 - val_loss: 0.8685 - val_accuracy: 0.7170\n",
            "Epoch 8/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.7167 - accuracy: 0.7600 - val_loss: 0.7121 - val_accuracy: 0.7602\n",
            "Epoch 9/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6780 - accuracy: 0.7688 - val_loss: 0.8594 - val_accuracy: 0.7098\n",
            "Epoch 10/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6534 - accuracy: 0.7788 - val_loss: 0.7211 - val_accuracy: 0.7634\n",
            "Epoch 11/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.6361 - accuracy: 0.7871 - val_loss: 0.5703 - val_accuracy: 0.8096\n",
            "Epoch 12/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.6148 - accuracy: 0.7934 - val_loss: 0.5734 - val_accuracy: 0.8062\n",
            "Epoch 13/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.5914 - accuracy: 0.8016 - val_loss: 0.6625 - val_accuracy: 0.7774\n",
            "Epoch 14/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.5835 - accuracy: 0.8047 - val_loss: 0.5518 - val_accuracy: 0.8112\n",
            "Epoch 15/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.5631 - accuracy: 0.8119 - val_loss: 0.5559 - val_accuracy: 0.8152\n",
            "Epoch 16/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5525 - accuracy: 0.8167 - val_loss: 0.6856 - val_accuracy: 0.7734\n",
            "Epoch 17/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.5433 - accuracy: 0.8160 - val_loss: 0.7360 - val_accuracy: 0.7554\n",
            "Epoch 18/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5304 - accuracy: 0.8215 - val_loss: 0.5095 - val_accuracy: 0.8330\n",
            "Epoch 19/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5148 - accuracy: 0.8274 - val_loss: 0.5677 - val_accuracy: 0.8090\n",
            "Epoch 20/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.5093 - accuracy: 0.8299 - val_loss: 0.6147 - val_accuracy: 0.7926\n",
            "Epoch 21/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4900 - accuracy: 0.8349 - val_loss: 0.5520 - val_accuracy: 0.8176\n",
            "Epoch 22/200\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4865 - accuracy: 0.8371 - val_loss: 0.6105 - val_accuracy: 0.7944\n",
            "Epoch 23/200\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.4769 - accuracy: 0.8401 - val_loss: 0.4734 - val_accuracy: 0.8378\n",
            "Epoch 24/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4696 - accuracy: 0.8433 - val_loss: 0.5397 - val_accuracy: 0.8220\n",
            "Epoch 25/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4708 - accuracy: 0.8430 - val_loss: 0.4599 - val_accuracy: 0.8422\n",
            "Epoch 26/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4573 - accuracy: 0.8468 - val_loss: 0.4652 - val_accuracy: 0.8440\n",
            "Epoch 27/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4434 - accuracy: 0.8512 - val_loss: 0.4853 - val_accuracy: 0.8342\n",
            "Epoch 28/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4391 - accuracy: 0.8522 - val_loss: 0.4451 - val_accuracy: 0.8510\n",
            "Epoch 29/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.4373 - accuracy: 0.8531 - val_loss: 0.4449 - val_accuracy: 0.8458\n",
            "Epoch 30/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4288 - accuracy: 0.8561 - val_loss: 0.5311 - val_accuracy: 0.8274\n",
            "Epoch 31/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.4206 - accuracy: 0.8595 - val_loss: 0.4344 - val_accuracy: 0.8542\n",
            "Epoch 32/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.4201 - accuracy: 0.8569 - val_loss: 0.4116 - val_accuracy: 0.8636\n",
            "Epoch 33/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.4096 - accuracy: 0.8620 - val_loss: 0.4415 - val_accuracy: 0.8548\n",
            "Epoch 34/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.4023 - accuracy: 0.8631 - val_loss: 0.4360 - val_accuracy: 0.8570\n",
            "Epoch 35/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3972 - accuracy: 0.8650 - val_loss: 0.4393 - val_accuracy: 0.8576\n",
            "Epoch 36/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3924 - accuracy: 0.8676 - val_loss: 0.4871 - val_accuracy: 0.8418\n",
            "Epoch 37/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3901 - accuracy: 0.8681 - val_loss: 0.3853 - val_accuracy: 0.8736\n",
            "Epoch 38/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.3874 - accuracy: 0.8700 - val_loss: 0.4650 - val_accuracy: 0.8490\n",
            "Epoch 39/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.3803 - accuracy: 0.8708 - val_loss: 0.4525 - val_accuracy: 0.8546\n",
            "Epoch 40/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3772 - accuracy: 0.8732 - val_loss: 0.4469 - val_accuracy: 0.8500\n",
            "Epoch 41/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3754 - accuracy: 0.8714 - val_loss: 0.3932 - val_accuracy: 0.8720\n",
            "Epoch 42/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.3714 - accuracy: 0.8755 - val_loss: 0.3970 - val_accuracy: 0.8718\n",
            "Epoch 43/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3683 - accuracy: 0.8760 - val_loss: 0.4344 - val_accuracy: 0.8566\n",
            "Epoch 44/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3607 - accuracy: 0.8778 - val_loss: 0.4799 - val_accuracy: 0.8454\n",
            "Epoch 45/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3660 - accuracy: 0.8762 - val_loss: 0.4409 - val_accuracy: 0.8578\n",
            "Epoch 46/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.3559 - accuracy: 0.8797 - val_loss: 0.4802 - val_accuracy: 0.8514\n",
            "Epoch 47/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.3549 - accuracy: 0.8809 - val_loss: 0.4196 - val_accuracy: 0.8670\n",
            "Epoch 48/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3530 - accuracy: 0.8798 - val_loss: 0.4090 - val_accuracy: 0.8694\n",
            "Epoch 49/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3460 - accuracy: 0.8827 - val_loss: 0.3593 - val_accuracy: 0.8800\n",
            "Epoch 50/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.3437 - accuracy: 0.8828 - val_loss: 0.4523 - val_accuracy: 0.8514\n",
            "Epoch 51/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3400 - accuracy: 0.8847 - val_loss: 0.4012 - val_accuracy: 0.8690\n",
            "Epoch 52/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.3341 - accuracy: 0.8853 - val_loss: 0.3550 - val_accuracy: 0.8802\n",
            "Epoch 53/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.3383 - accuracy: 0.8856 - val_loss: 0.3781 - val_accuracy: 0.8770\n",
            "Epoch 54/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.3292 - accuracy: 0.8874 - val_loss: 0.3934 - val_accuracy: 0.8730\n",
            "Epoch 55/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.3269 - accuracy: 0.8902 - val_loss: 0.4717 - val_accuracy: 0.8506\n",
            "Epoch 56/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.3203 - accuracy: 0.8887 - val_loss: 0.3773 - val_accuracy: 0.8768\n",
            "Epoch 57/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3234 - accuracy: 0.8904 - val_loss: 0.3745 - val_accuracy: 0.8798\n",
            "Epoch 58/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3170 - accuracy: 0.8916 - val_loss: 0.4500 - val_accuracy: 0.8534\n",
            "Epoch 59/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.3124 - accuracy: 0.8929 - val_loss: 0.3411 - val_accuracy: 0.8842\n",
            "Epoch 60/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.3159 - accuracy: 0.8918 - val_loss: 0.4381 - val_accuracy: 0.8566\n",
            "Epoch 61/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3139 - accuracy: 0.8914 - val_loss: 0.4326 - val_accuracy: 0.8582\n",
            "Epoch 62/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.3093 - accuracy: 0.8939 - val_loss: 0.3657 - val_accuracy: 0.8748\n",
            "Epoch 63/200\n",
            "703/703 [==============================] - 27s 38ms/step - loss: 0.3060 - accuracy: 0.8953 - val_loss: 0.3716 - val_accuracy: 0.8782\n",
            "Epoch 64/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3076 - accuracy: 0.8950 - val_loss: 0.3862 - val_accuracy: 0.8778\n",
            "Epoch 65/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3076 - accuracy: 0.8951 - val_loss: 0.3379 - val_accuracy: 0.8866\n",
            "Epoch 66/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3039 - accuracy: 0.8958 - val_loss: 0.3936 - val_accuracy: 0.8700\n",
            "Epoch 67/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2951 - accuracy: 0.8984 - val_loss: 0.4412 - val_accuracy: 0.8628\n",
            "Epoch 68/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2993 - accuracy: 0.8991 - val_loss: 0.3591 - val_accuracy: 0.8874\n",
            "Epoch 69/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.3005 - accuracy: 0.8971 - val_loss: 0.3703 - val_accuracy: 0.8784\n",
            "Epoch 70/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2916 - accuracy: 0.9011 - val_loss: 0.4006 - val_accuracy: 0.8694\n",
            "Epoch 71/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2913 - accuracy: 0.8997 - val_loss: 0.3677 - val_accuracy: 0.8808\n",
            "Epoch 72/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.2939 - accuracy: 0.9007 - val_loss: 0.3426 - val_accuracy: 0.8882\n",
            "Epoch 73/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2899 - accuracy: 0.9013 - val_loss: 0.3687 - val_accuracy: 0.8822\n",
            "Epoch 74/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2883 - accuracy: 0.9010 - val_loss: 0.4064 - val_accuracy: 0.8642\n",
            "Epoch 75/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2882 - accuracy: 0.9028 - val_loss: 0.3775 - val_accuracy: 0.8760\n",
            "Epoch 76/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2799 - accuracy: 0.9034 - val_loss: 0.3821 - val_accuracy: 0.8790\n",
            "Epoch 77/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2834 - accuracy: 0.9036 - val_loss: 0.3647 - val_accuracy: 0.8868\n",
            "Epoch 78/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2867 - accuracy: 0.9015 - val_loss: 0.3346 - val_accuracy: 0.8904\n",
            "Epoch 79/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2858 - accuracy: 0.9026 - val_loss: 0.3613 - val_accuracy: 0.8840\n",
            "Epoch 80/200\n",
            "703/703 [==============================] - 27s 38ms/step - loss: 0.2786 - accuracy: 0.9035 - val_loss: 0.3307 - val_accuracy: 0.8914\n",
            "Epoch 81/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2752 - accuracy: 0.9068 - val_loss: 0.4360 - val_accuracy: 0.8640\n",
            "Epoch 82/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2767 - accuracy: 0.9052 - val_loss: 0.3529 - val_accuracy: 0.8888\n",
            "Epoch 83/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2760 - accuracy: 0.9054 - val_loss: 0.3495 - val_accuracy: 0.8920\n",
            "Epoch 84/200\n",
            "703/703 [==============================] - 24s 34ms/step - loss: 0.2726 - accuracy: 0.9058 - val_loss: 0.4522 - val_accuracy: 0.8556\n",
            "Epoch 85/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2717 - accuracy: 0.9073 - val_loss: 0.3289 - val_accuracy: 0.8944\n",
            "Epoch 86/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2690 - accuracy: 0.9071 - val_loss: 0.3314 - val_accuracy: 0.8912\n",
            "Epoch 87/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2711 - accuracy: 0.9069 - val_loss: 0.4130 - val_accuracy: 0.8666\n",
            "Epoch 88/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.2686 - accuracy: 0.9094 - val_loss: 0.3606 - val_accuracy: 0.8812\n",
            "Epoch 89/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2673 - accuracy: 0.9081 - val_loss: 0.4450 - val_accuracy: 0.8678\n",
            "Epoch 90/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2656 - accuracy: 0.9092 - val_loss: 0.3550 - val_accuracy: 0.8838\n",
            "Epoch 91/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2683 - accuracy: 0.9090 - val_loss: 0.4184 - val_accuracy: 0.8702\n",
            "Epoch 92/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2653 - accuracy: 0.9073 - val_loss: 0.3536 - val_accuracy: 0.8900\n",
            "Epoch 93/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2605 - accuracy: 0.9119 - val_loss: 0.3516 - val_accuracy: 0.8908\n",
            "Epoch 94/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2623 - accuracy: 0.9095 - val_loss: 0.3522 - val_accuracy: 0.8876\n",
            "Epoch 95/200\n",
            "703/703 [==============================] - 27s 38ms/step - loss: 0.2595 - accuracy: 0.9111 - val_loss: 0.3419 - val_accuracy: 0.8842\n",
            "Epoch 96/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2563 - accuracy: 0.9131 - val_loss: 0.3603 - val_accuracy: 0.8870\n",
            "Epoch 97/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2545 - accuracy: 0.9110 - val_loss: 0.4521 - val_accuracy: 0.8620\n",
            "Epoch 98/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2580 - accuracy: 0.9128 - val_loss: 0.3498 - val_accuracy: 0.8860\n",
            "Epoch 99/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2564 - accuracy: 0.9107 - val_loss: 0.3406 - val_accuracy: 0.8902\n",
            "Epoch 100/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2566 - accuracy: 0.9129 - val_loss: 0.3561 - val_accuracy: 0.8892\n",
            "Epoch 101/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2519 - accuracy: 0.9143 - val_loss: 0.3500 - val_accuracy: 0.8860\n",
            "Epoch 102/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2581 - accuracy: 0.9124 - val_loss: 0.3730 - val_accuracy: 0.8820\n",
            "Epoch 103/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2526 - accuracy: 0.9139 - val_loss: 0.3367 - val_accuracy: 0.8900\n",
            "Epoch 104/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2512 - accuracy: 0.9137 - val_loss: 0.3439 - val_accuracy: 0.8874\n",
            "Epoch 105/200\n",
            "703/703 [==============================] - 27s 39ms/step - loss: 0.2555 - accuracy: 0.9120 - val_loss: 0.3431 - val_accuracy: 0.8890\n",
            "Epoch 106/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2455 - accuracy: 0.9152 - val_loss: 0.3620 - val_accuracy: 0.8864\n",
            "Epoch 107/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2441 - accuracy: 0.9175 - val_loss: 0.3325 - val_accuracy: 0.8970\n",
            "Epoch 108/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2453 - accuracy: 0.9153 - val_loss: 0.3478 - val_accuracy: 0.8832\n",
            "Epoch 109/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2442 - accuracy: 0.9159 - val_loss: 0.3444 - val_accuracy: 0.8912\n",
            "Epoch 110/200\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.2454 - accuracy: 0.9153 - val_loss: 0.3289 - val_accuracy: 0.8944\n",
            "Epoch 111/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2448 - accuracy: 0.9155 - val_loss: 0.3475 - val_accuracy: 0.8838\n",
            "Epoch 112/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2397 - accuracy: 0.9183 - val_loss: 0.3696 - val_accuracy: 0.8816\n",
            "Epoch 113/200\n",
            "703/703 [==============================] - 27s 39ms/step - loss: 0.2403 - accuracy: 0.9183 - val_loss: 0.3586 - val_accuracy: 0.8872\n",
            "Epoch 114/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2385 - accuracy: 0.9178 - val_loss: 0.3366 - val_accuracy: 0.8922\n",
            "Epoch 115/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2357 - accuracy: 0.9185 - val_loss: 0.3858 - val_accuracy: 0.8786\n",
            "Epoch 116/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.2334 - accuracy: 0.9197 - val_loss: 0.3839 - val_accuracy: 0.8852\n",
            "Epoch 117/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2387 - accuracy: 0.9172 - val_loss: 0.4248 - val_accuracy: 0.8724\n",
            "Epoch 118/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2359 - accuracy: 0.9185 - val_loss: 0.3797 - val_accuracy: 0.8810\n",
            "Epoch 119/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2329 - accuracy: 0.9189 - val_loss: 0.3533 - val_accuracy: 0.8862\n",
            "Epoch 120/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2358 - accuracy: 0.9185 - val_loss: 0.3932 - val_accuracy: 0.8798\n",
            "Epoch 121/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2346 - accuracy: 0.9199 - val_loss: 0.3462 - val_accuracy: 0.8886\n",
            "Epoch 122/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2346 - accuracy: 0.9189 - val_loss: 0.3469 - val_accuracy: 0.8886\n",
            "Epoch 123/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2321 - accuracy: 0.9209 - val_loss: 0.3332 - val_accuracy: 0.8966\n",
            "Epoch 124/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2329 - accuracy: 0.9186 - val_loss: 0.3388 - val_accuracy: 0.8926\n",
            "Epoch 125/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2295 - accuracy: 0.9219 - val_loss: 0.3725 - val_accuracy: 0.8918\n",
            "Epoch 126/200\n",
            "703/703 [==============================] - 24s 35ms/step - loss: 0.2329 - accuracy: 0.9206 - val_loss: 0.3355 - val_accuracy: 0.8894\n",
            "Epoch 127/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.2382 - accuracy: 0.9194 - val_loss: 0.3489 - val_accuracy: 0.8944\n",
            "Epoch 128/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2301 - accuracy: 0.9222 - val_loss: 0.3708 - val_accuracy: 0.8852\n",
            "Epoch 129/200\n",
            "703/703 [==============================] - 26s 38ms/step - loss: 0.2238 - accuracy: 0.9231 - val_loss: 0.3261 - val_accuracy: 0.8908\n",
            "Epoch 130/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2271 - accuracy: 0.9224 - val_loss: 0.3634 - val_accuracy: 0.8900\n",
            "Epoch 131/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2254 - accuracy: 0.9227 - val_loss: 0.3499 - val_accuracy: 0.8856\n",
            "Epoch 132/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2243 - accuracy: 0.9218 - val_loss: 0.3461 - val_accuracy: 0.8904\n",
            "Epoch 133/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2286 - accuracy: 0.9218 - val_loss: 0.3408 - val_accuracy: 0.8910\n",
            "Epoch 134/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2205 - accuracy: 0.9234 - val_loss: 0.3217 - val_accuracy: 0.8958\n",
            "Epoch 135/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2267 - accuracy: 0.9230 - val_loss: 0.3337 - val_accuracy: 0.8904\n",
            "Epoch 136/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2181 - accuracy: 0.9238 - val_loss: 0.4341 - val_accuracy: 0.8730\n",
            "Epoch 137/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2244 - accuracy: 0.9231 - val_loss: 0.3285 - val_accuracy: 0.8960\n",
            "Epoch 138/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2300 - accuracy: 0.9216 - val_loss: 0.3652 - val_accuracy: 0.8900\n",
            "Epoch 139/200\n",
            "703/703 [==============================] - 27s 38ms/step - loss: 0.2219 - accuracy: 0.9228 - val_loss: 0.4182 - val_accuracy: 0.8736\n",
            "Epoch 140/200\n",
            "703/703 [==============================] - 27s 38ms/step - loss: 0.2211 - accuracy: 0.9249 - val_loss: 0.3278 - val_accuracy: 0.8998\n",
            "Epoch 141/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2178 - accuracy: 0.9243 - val_loss: 0.3913 - val_accuracy: 0.8784\n",
            "Epoch 142/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2161 - accuracy: 0.9244 - val_loss: 0.3532 - val_accuracy: 0.8928\n",
            "Epoch 143/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2197 - accuracy: 0.9241 - val_loss: 0.3410 - val_accuracy: 0.8878\n",
            "Epoch 144/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2190 - accuracy: 0.9255 - val_loss: 0.3618 - val_accuracy: 0.8892\n",
            "Epoch 145/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2178 - accuracy: 0.9249 - val_loss: 0.3558 - val_accuracy: 0.8852\n",
            "Epoch 146/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2178 - accuracy: 0.9252 - val_loss: 0.3214 - val_accuracy: 0.8984\n",
            "Epoch 147/200\n",
            "703/703 [==============================] - 26s 38ms/step - loss: 0.2233 - accuracy: 0.9222 - val_loss: 0.3415 - val_accuracy: 0.8894\n",
            "Epoch 148/200\n",
            "703/703 [==============================] - 27s 38ms/step - loss: 0.2191 - accuracy: 0.9241 - val_loss: 0.3142 - val_accuracy: 0.8944\n",
            "Epoch 149/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2163 - accuracy: 0.9264 - val_loss: 0.3733 - val_accuracy: 0.8858\n",
            "Epoch 150/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.2144 - accuracy: 0.9261 - val_loss: 0.3203 - val_accuracy: 0.8982\n",
            "Epoch 151/200\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.2225 - accuracy: 0.9251 - val_loss: 0.3308 - val_accuracy: 0.8984\n",
            "Epoch 152/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.2192 - accuracy: 0.9237 - val_loss: 0.3299 - val_accuracy: 0.8934\n",
            "Epoch 153/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2184 - accuracy: 0.9255 - val_loss: 0.3710 - val_accuracy: 0.8852\n",
            "Epoch 154/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2103 - accuracy: 0.9265 - val_loss: 0.3246 - val_accuracy: 0.8948\n",
            "Epoch 155/200\n",
            "703/703 [==============================] - 27s 38ms/step - loss: 0.2117 - accuracy: 0.9274 - val_loss: 0.3655 - val_accuracy: 0.8926\n",
            "Epoch 156/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2140 - accuracy: 0.9272 - val_loss: 0.3776 - val_accuracy: 0.8858\n",
            "Epoch 157/200\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.2098 - accuracy: 0.9278 - val_loss: 0.3267 - val_accuracy: 0.8918\n",
            "Epoch 158/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2130 - accuracy: 0.9272 - val_loss: 0.3548 - val_accuracy: 0.8936\n",
            "Epoch 159/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2072 - accuracy: 0.9284 - val_loss: 0.3301 - val_accuracy: 0.8976\n",
            "Epoch 160/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2112 - accuracy: 0.9269 - val_loss: 0.3498 - val_accuracy: 0.8908\n",
            "Epoch 161/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2142 - accuracy: 0.9263 - val_loss: 0.3406 - val_accuracy: 0.8938\n",
            "Epoch 162/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2101 - accuracy: 0.9272 - val_loss: 0.3231 - val_accuracy: 0.9040\n",
            "Epoch 163/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2112 - accuracy: 0.9277 - val_loss: 0.3080 - val_accuracy: 0.8986\n",
            "Epoch 164/200\n",
            "703/703 [==============================] - 28s 40ms/step - loss: 0.2083 - accuracy: 0.9293 - val_loss: 0.3458 - val_accuracy: 0.8978\n",
            "Epoch 165/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2098 - accuracy: 0.9276 - val_loss: 0.3502 - val_accuracy: 0.8918\n",
            "Epoch 166/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2057 - accuracy: 0.9296 - val_loss: 0.3447 - val_accuracy: 0.8982\n",
            "Epoch 167/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2060 - accuracy: 0.9286 - val_loss: 0.3374 - val_accuracy: 0.9034\n",
            "Epoch 168/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2012 - accuracy: 0.9301 - val_loss: 0.3215 - val_accuracy: 0.9012\n",
            "Epoch 169/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2048 - accuracy: 0.9282 - val_loss: 0.3567 - val_accuracy: 0.8940\n",
            "Epoch 170/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2046 - accuracy: 0.9297 - val_loss: 0.3327 - val_accuracy: 0.8950\n",
            "Epoch 171/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2079 - accuracy: 0.9289 - val_loss: 0.3775 - val_accuracy: 0.8834\n",
            "Epoch 172/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.2052 - accuracy: 0.9292 - val_loss: 0.3242 - val_accuracy: 0.8998\n",
            "Epoch 173/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2063 - accuracy: 0.9279 - val_loss: 0.3680 - val_accuracy: 0.8866\n",
            "Epoch 174/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2028 - accuracy: 0.9306 - val_loss: 0.3405 - val_accuracy: 0.8976\n",
            "Epoch 175/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2022 - accuracy: 0.9292 - val_loss: 0.3364 - val_accuracy: 0.8954\n",
            "Epoch 176/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2007 - accuracy: 0.9327 - val_loss: 0.3818 - val_accuracy: 0.8828\n",
            "Epoch 177/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.1973 - accuracy: 0.9326 - val_loss: 0.3410 - val_accuracy: 0.8984\n",
            "Epoch 178/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.2023 - accuracy: 0.9307 - val_loss: 0.3913 - val_accuracy: 0.8772\n",
            "Epoch 179/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2015 - accuracy: 0.9299 - val_loss: 0.3544 - val_accuracy: 0.8950\n",
            "Epoch 180/200\n",
            "703/703 [==============================] - 25s 35ms/step - loss: 0.1972 - accuracy: 0.9314 - val_loss: 0.3716 - val_accuracy: 0.8898\n",
            "Epoch 181/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2009 - accuracy: 0.9299 - val_loss: 0.3302 - val_accuracy: 0.8970\n",
            "Epoch 182/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.1987 - accuracy: 0.9327 - val_loss: 0.3340 - val_accuracy: 0.8962\n",
            "Epoch 183/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2036 - accuracy: 0.9306 - val_loss: 0.3547 - val_accuracy: 0.8944\n",
            "Epoch 184/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.1986 - accuracy: 0.9315 - val_loss: 0.3633 - val_accuracy: 0.8930\n",
            "Epoch 185/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.1941 - accuracy: 0.9341 - val_loss: 0.3787 - val_accuracy: 0.8910\n",
            "Epoch 186/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.1975 - accuracy: 0.9313 - val_loss: 0.3270 - val_accuracy: 0.9034\n",
            "Epoch 187/200\n",
            "703/703 [==============================] - 25s 36ms/step - loss: 0.2012 - accuracy: 0.9316 - val_loss: 0.3365 - val_accuracy: 0.8992\n",
            "Epoch 188/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.1980 - accuracy: 0.9317 - val_loss: 0.3562 - val_accuracy: 0.8972\n",
            "Epoch 189/200\n",
            "703/703 [==============================] - 27s 39ms/step - loss: 0.1962 - accuracy: 0.9321 - val_loss: 0.3281 - val_accuracy: 0.9016\n",
            "Epoch 190/200\n",
            "703/703 [==============================] - 31s 44ms/step - loss: 0.1978 - accuracy: 0.9321 - val_loss: 0.3367 - val_accuracy: 0.9012\n",
            "Epoch 191/200\n",
            "703/703 [==============================] - 39s 55ms/step - loss: 0.1943 - accuracy: 0.9333 - val_loss: 0.3258 - val_accuracy: 0.9082\n",
            "Epoch 192/200\n",
            "703/703 [==============================] - 50s 71ms/step - loss: 0.1957 - accuracy: 0.9326 - val_loss: 0.3281 - val_accuracy: 0.9028\n",
            "Epoch 193/200\n",
            "703/703 [==============================] - 35s 50ms/step - loss: 0.1945 - accuracy: 0.9321 - val_loss: 0.3200 - val_accuracy: 0.9016\n",
            "Epoch 194/200\n",
            "703/703 [==============================] - 34s 49ms/step - loss: 0.1923 - accuracy: 0.9338 - val_loss: 0.3579 - val_accuracy: 0.9006\n",
            "Epoch 195/200\n",
            "703/703 [==============================] - 32s 45ms/step - loss: 0.1916 - accuracy: 0.9345 - val_loss: 0.3364 - val_accuracy: 0.9014\n",
            "Epoch 196/200\n",
            "703/703 [==============================] - 29s 41ms/step - loss: 0.1926 - accuracy: 0.9325 - val_loss: 0.3458 - val_accuracy: 0.8972\n",
            "Epoch 197/200\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.1983 - accuracy: 0.9326 - val_loss: 0.3399 - val_accuracy: 0.8986\n",
            "Epoch 198/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.1943 - accuracy: 0.9333 - val_loss: 0.3454 - val_accuracy: 0.8966\n",
            "Epoch 199/200\n",
            "703/703 [==============================] - 26s 36ms/step - loss: 0.1909 - accuracy: 0.9347 - val_loss: 0.3265 - val_accuracy: 0.9000\n",
            "Epoch 200/200\n",
            "703/703 [==============================] - 26s 37ms/step - loss: 0.1868 - accuracy: 0.9352 - val_loss: 0.3393 - val_accuracy: 0.8998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Visualization"
      ],
      "metadata": {
        "id": "P383F_7Cgg0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training and validation performance\n",
        "f,ax=plt.subplots(2,1) \n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[0].plot(history_9.history['loss'], color='b',label='Training Loss')\n",
        "ax[0].plot(history_9.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[1].plot(history_9.history['accuracy'],color='b',label='Training Accuracy')\n",
        "ax[1].plot(history_9.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "x9UHCt1u1woB",
        "outputId": "47bbd5be-5413-467a-9450-cdf57bf5c54e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb5f051c970>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate model on test set"
      ],
      "metadata": {
        "id": "5lJRXkl_glPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the model performance\n",
        "result = model_9.evaluate(X_test_norm, y_test)\n",
        "print('Loss and accuracy on the test set: loss = {}, accuracy = {}'.format(result[0], result[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAWNzcPLlRYw",
        "outputId": "709429a8-5b3d-4811-bbeb-a4f0f72d0c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.3242 - accuracy: 0.8987\n",
            "Loss and accuracy on the test set: loss = 0.3242151737213135, accuracy = 0.8986999988555908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model_9.save('model_9.h5')"
      ],
      "metadata": {
        "id": "XYJWBJ_dlNaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other model architectures trials and their results:"
      ],
      "metadata": {
        "id": "YFyvJUogeHAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 1: 3 blocks of 2xConv2D and 1xMaxPool, epoch = 50"
      ],
      "metadata": {
        "id": "VngLX2Ev4Lq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to improve: \n",
        "*   More epochs\n",
        "*   More Conv2D blocks\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QUs2smGM6y-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=X_train_norm[0].shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuSGQTv_4J40",
        "outputId": "c3ebedd8-450c-4597-f54e-a9d4291828b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,397,226\n",
            "Trainable params: 2,396,330\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training and validation performance\n",
        "f,ax=plt.subplots(2,1) \n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[0].plot(history.history['loss'], color='b',label='Training Loss')\n",
        "ax[0].plot(history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[1].plot(history.history['accuracy'],color='b',label='Training Accuracy')\n",
        "ax[1].plot(history.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "15sCE7Vz5rEr",
        "outputId": "9989c666-a809-45cd-f1b7-d526916b9323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f74a6300e80>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, # Define loss function\n",
        "                optimizer= tf.keras.optimizers.Adam(learning_rate=1e-2), metrics=['accuracy']) # Define initial learning rate and metrics.\n",
        "\n",
        "# Train the model. Using Colab for training\n",
        "history = model.fit(X_train_norm, y_train, # Data feature and data label\n",
        "                    batch_size=1024, # Batch size\n",
        "                    epochs=50, # Number of training epochs\n",
        "                    validation_data=(X_val_norm, y_val)) # Validation set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IvpXNft4bM0",
        "outputId": "a1926e28-5a52-4810-8428-8d68762649de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "44/44 [==============================] - 19s 189ms/step - loss: 8.1735 - accuracy: 0.2126 - val_loss: 7.6385 - val_accuracy: 0.1240\n",
            "Epoch 2/50\n",
            "44/44 [==============================] - 5s 103ms/step - loss: 1.9667 - accuracy: 0.3101 - val_loss: 5.8682 - val_accuracy: 0.1108\n",
            "Epoch 3/50\n",
            "44/44 [==============================] - 5s 104ms/step - loss: 1.6800 - accuracy: 0.3799 - val_loss: 4.1914 - val_accuracy: 0.1628\n",
            "Epoch 4/50\n",
            "44/44 [==============================] - 5s 104ms/step - loss: 1.5586 - accuracy: 0.4272 - val_loss: 2.2248 - val_accuracy: 0.2442\n",
            "Epoch 5/50\n",
            "44/44 [==============================] - 5s 104ms/step - loss: 1.4556 - accuracy: 0.4648 - val_loss: 1.9035 - val_accuracy: 0.3230\n",
            "Epoch 6/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 1.3550 - accuracy: 0.5094 - val_loss: 2.6689 - val_accuracy: 0.2342\n",
            "Epoch 7/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 1.2808 - accuracy: 0.5367 - val_loss: 2.6560 - val_accuracy: 0.2668\n",
            "Epoch 8/50\n",
            "44/44 [==============================] - 5s 107ms/step - loss: 1.2157 - accuracy: 0.5618 - val_loss: 2.3613 - val_accuracy: 0.3218\n",
            "Epoch 9/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 1.1451 - accuracy: 0.5898 - val_loss: 2.0355 - val_accuracy: 0.3764\n",
            "Epoch 10/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 1.0771 - accuracy: 0.6173 - val_loss: 2.1078 - val_accuracy: 0.4880\n",
            "Epoch 11/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 1.0211 - accuracy: 0.6371 - val_loss: 1.1586 - val_accuracy: 0.6000\n",
            "Epoch 12/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.9585 - accuracy: 0.6594 - val_loss: 1.9561 - val_accuracy: 0.5308\n",
            "Epoch 13/50\n",
            "44/44 [==============================] - 5s 107ms/step - loss: 0.8992 - accuracy: 0.6813 - val_loss: 1.3612 - val_accuracy: 0.5752\n",
            "Epoch 14/50\n",
            "44/44 [==============================] - 5s 107ms/step - loss: 0.8457 - accuracy: 0.7042 - val_loss: 1.1475 - val_accuracy: 0.6324\n",
            "Epoch 15/50\n",
            "44/44 [==============================] - 5s 107ms/step - loss: 0.7954 - accuracy: 0.7212 - val_loss: 1.3470 - val_accuracy: 0.6464\n",
            "Epoch 16/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.7437 - accuracy: 0.7405 - val_loss: 1.1810 - val_accuracy: 0.6252\n",
            "Epoch 17/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.7113 - accuracy: 0.7503 - val_loss: 1.2003 - val_accuracy: 0.6288\n",
            "Epoch 18/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.6635 - accuracy: 0.7651 - val_loss: 1.2253 - val_accuracy: 0.6384\n",
            "Epoch 19/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.6170 - accuracy: 0.7827 - val_loss: 0.9575 - val_accuracy: 0.7048\n",
            "Epoch 20/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.5758 - accuracy: 0.7976 - val_loss: 1.1149 - val_accuracy: 0.6770\n",
            "Epoch 21/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.5360 - accuracy: 0.8116 - val_loss: 1.0049 - val_accuracy: 0.7046\n",
            "Epoch 22/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.5169 - accuracy: 0.8146 - val_loss: 0.8898 - val_accuracy: 0.7330\n",
            "Epoch 23/50\n",
            "44/44 [==============================] - 5s 107ms/step - loss: 0.4771 - accuracy: 0.8314 - val_loss: 0.8825 - val_accuracy: 0.7510\n",
            "Epoch 24/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.4548 - accuracy: 0.8380 - val_loss: 1.0097 - val_accuracy: 0.7118\n",
            "Epoch 25/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.4212 - accuracy: 0.8515 - val_loss: 0.9513 - val_accuracy: 0.7128\n",
            "Epoch 26/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.4014 - accuracy: 0.8588 - val_loss: 0.9097 - val_accuracy: 0.7394\n",
            "Epoch 27/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.3752 - accuracy: 0.8678 - val_loss: 0.8435 - val_accuracy: 0.7480\n",
            "Epoch 28/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.3524 - accuracy: 0.8754 - val_loss: 0.8174 - val_accuracy: 0.7558\n",
            "Epoch 29/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.3292 - accuracy: 0.8824 - val_loss: 0.8381 - val_accuracy: 0.7638\n",
            "Epoch 30/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.3171 - accuracy: 0.8875 - val_loss: 0.8632 - val_accuracy: 0.7542\n",
            "Epoch 31/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.3012 - accuracy: 0.8941 - val_loss: 0.8181 - val_accuracy: 0.7708\n",
            "Epoch 32/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.2923 - accuracy: 0.8952 - val_loss: 0.9564 - val_accuracy: 0.7440\n",
            "Epoch 33/50\n",
            "44/44 [==============================] - 5s 105ms/step - loss: 0.2704 - accuracy: 0.9062 - val_loss: 0.9223 - val_accuracy: 0.7518\n",
            "Epoch 34/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.2607 - accuracy: 0.9089 - val_loss: 1.0081 - val_accuracy: 0.7476\n",
            "Epoch 35/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.2435 - accuracy: 0.9144 - val_loss: 0.9623 - val_accuracy: 0.7638\n",
            "Epoch 36/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.2310 - accuracy: 0.9184 - val_loss: 0.8644 - val_accuracy: 0.7676\n",
            "Epoch 37/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.2202 - accuracy: 0.9239 - val_loss: 1.0045 - val_accuracy: 0.7498\n",
            "Epoch 38/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.2060 - accuracy: 0.9275 - val_loss: 0.9081 - val_accuracy: 0.7594\n",
            "Epoch 39/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.2060 - accuracy: 0.9273 - val_loss: 0.9923 - val_accuracy: 0.7762\n",
            "Epoch 40/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.2005 - accuracy: 0.9292 - val_loss: 0.9696 - val_accuracy: 0.7624\n",
            "Epoch 41/50\n",
            "44/44 [==============================] - 5s 108ms/step - loss: 0.1893 - accuracy: 0.9347 - val_loss: 1.0148 - val_accuracy: 0.7558\n",
            "Epoch 42/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1863 - accuracy: 0.9361 - val_loss: 0.8380 - val_accuracy: 0.7828\n",
            "Epoch 43/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1756 - accuracy: 0.9398 - val_loss: 0.9843 - val_accuracy: 0.7666\n",
            "Epoch 44/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1848 - accuracy: 0.9369 - val_loss: 0.9475 - val_accuracy: 0.7684\n",
            "Epoch 45/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1661 - accuracy: 0.9428 - val_loss: 1.0279 - val_accuracy: 0.7698\n",
            "Epoch 46/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1623 - accuracy: 0.9450 - val_loss: 0.8997 - val_accuracy: 0.7794\n",
            "Epoch 47/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1512 - accuracy: 0.9492 - val_loss: 0.8643 - val_accuracy: 0.7812\n",
            "Epoch 48/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1402 - accuracy: 0.9517 - val_loss: 0.9689 - val_accuracy: 0.7774\n",
            "Epoch 49/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1416 - accuracy: 0.9543 - val_loss: 0.9790 - val_accuracy: 0.7744\n",
            "Epoch 50/50\n",
            "44/44 [==============================] - 5s 106ms/step - loss: 0.1537 - accuracy: 0.9487 - val_loss: 0.8791 - val_accuracy: 0.7828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc = model.evaluate(X_test_norm, y_test, verbose = 0)\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGsBHiua6CZQ",
        "outputId": "ceeadec3-74d9-427e-a563-933563181d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7849000096321106"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model 2: 2 blocks of (2xConv2D + 1xMaxPool) and 3 blocks of (3xConv2D + 1xMaxPool) and 2 Dropout before Dense layers, epoch = 50"
      ],
      "metadata": {
        "id": "S8LbCRiI-b1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to improve:\n",
        "\n",
        "*   More epochs\n",
        "*   Try different dropout rates\n",
        "\n"
      ],
      "metadata": {
        "id": "YzarIoHIfLp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=X_train_norm[0].shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_2 = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJteK_EX-6i3",
        "outputId": "3b0ea0f0-166a-43cc-aa5d-782b4da8912c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 4, 4, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,975,146\n",
            "Trainable params: 2,972,458\n",
            "Non-trainable params: 2,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, # Define loss function\n",
        "                optimizer= tf.keras.optimizers.Adam(learning_rate=1e-2), metrics=['accuracy']) # Define initial learning rate and metrics.\n",
        "\n",
        "# Train the model. Using Colab for training\n",
        "history_2 = model_2.fit(X_train_norm, y_train, # Data feature and data label\n",
        "                    batch_size=1024, # Batch size\n",
        "                    epochs=50, # Number of training epochs\n",
        "                    validation_data=(X_val_norm, y_val)) # Validation set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBwf5jvt_Wf8",
        "outputId": "f97087ee-ade0-49c0-81b1-e78490846330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "44/44 [==============================] - 11s 202ms/step - loss: 6.4777 - accuracy: 0.1682 - val_loss: 3218.1216 - val_accuracy: 0.0962\n",
            "Epoch 2/50\n",
            "44/44 [==============================] - 6s 141ms/step - loss: 2.1342 - accuracy: 0.2791 - val_loss: 4.8127 - val_accuracy: 0.1444\n",
            "Epoch 3/50\n",
            "44/44 [==============================] - 6s 141ms/step - loss: 1.7358 - accuracy: 0.3483 - val_loss: 3.2184 - val_accuracy: 0.1414\n",
            "Epoch 4/50\n",
            "44/44 [==============================] - 6s 140ms/step - loss: 1.6164 - accuracy: 0.3931 - val_loss: 3.8046 - val_accuracy: 0.1540\n",
            "Epoch 5/50\n",
            "44/44 [==============================] - 6s 140ms/step - loss: 1.5182 - accuracy: 0.4294 - val_loss: 3.1263 - val_accuracy: 0.1776\n",
            "Epoch 6/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 1.4252 - accuracy: 0.4737 - val_loss: 2.1925 - val_accuracy: 0.2320\n",
            "Epoch 7/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 1.3398 - accuracy: 0.5090 - val_loss: 2.3102 - val_accuracy: 0.2526\n",
            "Epoch 8/50\n",
            "44/44 [==============================] - 6s 138ms/step - loss: 1.2475 - accuracy: 0.5476 - val_loss: 2.2473 - val_accuracy: 0.2632\n",
            "Epoch 9/50\n",
            "44/44 [==============================] - 6s 141ms/step - loss: 1.1769 - accuracy: 0.5747 - val_loss: 2.0839 - val_accuracy: 0.3128\n",
            "Epoch 10/50\n",
            "44/44 [==============================] - 6s 138ms/step - loss: 1.1014 - accuracy: 0.6018 - val_loss: 1.6912 - val_accuracy: 0.3910\n",
            "Epoch 11/50\n",
            "44/44 [==============================] - 6s 138ms/step - loss: 1.0221 - accuracy: 0.6348 - val_loss: 1.9184 - val_accuracy: 0.4074\n",
            "Epoch 12/50\n",
            "44/44 [==============================] - 6s 138ms/step - loss: 0.9546 - accuracy: 0.6585 - val_loss: 1.3372 - val_accuracy: 0.5274\n",
            "Epoch 13/50\n",
            "44/44 [==============================] - 6s 138ms/step - loss: 0.8941 - accuracy: 0.6830 - val_loss: 1.2698 - val_accuracy: 0.5636\n",
            "Epoch 14/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.8365 - accuracy: 0.7011 - val_loss: 1.2929 - val_accuracy: 0.5734\n",
            "Epoch 15/50\n",
            "44/44 [==============================] - 6s 142ms/step - loss: 0.7872 - accuracy: 0.7225 - val_loss: 1.1101 - val_accuracy: 0.6186\n",
            "Epoch 16/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.7416 - accuracy: 0.7386 - val_loss: 1.3434 - val_accuracy: 0.5854\n",
            "Epoch 17/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.6968 - accuracy: 0.7572 - val_loss: 1.0468 - val_accuracy: 0.6496\n",
            "Epoch 18/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.6415 - accuracy: 0.7769 - val_loss: 0.8611 - val_accuracy: 0.6996\n",
            "Epoch 19/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.6078 - accuracy: 0.7889 - val_loss: 0.8483 - val_accuracy: 0.7118\n",
            "Epoch 20/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.5756 - accuracy: 0.8023 - val_loss: 0.9202 - val_accuracy: 0.6926\n",
            "Epoch 21/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.5792 - accuracy: 0.7990 - val_loss: 1.3526 - val_accuracy: 0.5920\n",
            "Epoch 22/50\n",
            "44/44 [==============================] - 6s 143ms/step - loss: 0.5368 - accuracy: 0.8126 - val_loss: 1.2760 - val_accuracy: 0.6116\n",
            "Epoch 23/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.4879 - accuracy: 0.8312 - val_loss: 0.9171 - val_accuracy: 0.7100\n",
            "Epoch 24/50\n",
            "44/44 [==============================] - 6s 142ms/step - loss: 0.4549 - accuracy: 0.8425 - val_loss: 0.8596 - val_accuracy: 0.7184\n",
            "Epoch 25/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.4244 - accuracy: 0.8546 - val_loss: 1.0131 - val_accuracy: 0.7024\n",
            "Epoch 26/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.3879 - accuracy: 0.8655 - val_loss: 0.7695 - val_accuracy: 0.7596\n",
            "Epoch 27/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.3653 - accuracy: 0.8740 - val_loss: 0.9499 - val_accuracy: 0.7174\n",
            "Epoch 28/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.3541 - accuracy: 0.8785 - val_loss: 0.9002 - val_accuracy: 0.7352\n",
            "Epoch 29/50\n",
            "44/44 [==============================] - 6s 142ms/step - loss: 0.3233 - accuracy: 0.8888 - val_loss: 1.0423 - val_accuracy: 0.7132\n",
            "Epoch 30/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.2960 - accuracy: 0.8987 - val_loss: 0.9482 - val_accuracy: 0.7416\n",
            "Epoch 31/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.2897 - accuracy: 0.9002 - val_loss: 1.2099 - val_accuracy: 0.7068\n",
            "Epoch 32/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.2753 - accuracy: 0.9060 - val_loss: 0.9226 - val_accuracy: 0.7456\n",
            "Epoch 33/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.2481 - accuracy: 0.9144 - val_loss: 1.0666 - val_accuracy: 0.7398\n",
            "Epoch 34/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.2346 - accuracy: 0.9180 - val_loss: 1.0319 - val_accuracy: 0.7368\n",
            "Epoch 35/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.2208 - accuracy: 0.9253 - val_loss: 1.2314 - val_accuracy: 0.7166\n",
            "Epoch 36/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1951 - accuracy: 0.9330 - val_loss: 1.3537 - val_accuracy: 0.7172\n",
            "Epoch 37/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1855 - accuracy: 0.9359 - val_loss: 1.2269 - val_accuracy: 0.7228\n",
            "Epoch 38/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1759 - accuracy: 0.9400 - val_loss: 1.1066 - val_accuracy: 0.7614\n",
            "Epoch 39/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1638 - accuracy: 0.9438 - val_loss: 1.1570 - val_accuracy: 0.7464\n",
            "Epoch 40/50\n",
            "44/44 [==============================] - 6s 142ms/step - loss: 0.1528 - accuracy: 0.9483 - val_loss: 1.2860 - val_accuracy: 0.7474\n",
            "Epoch 41/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1521 - accuracy: 0.9469 - val_loss: 1.1316 - val_accuracy: 0.7636\n",
            "Epoch 42/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1349 - accuracy: 0.9541 - val_loss: 1.5306 - val_accuracy: 0.7018\n",
            "Epoch 43/50\n",
            "44/44 [==============================] - 6s 140ms/step - loss: 0.1334 - accuracy: 0.9549 - val_loss: 1.0615 - val_accuracy: 0.7602\n",
            "Epoch 44/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1233 - accuracy: 0.9576 - val_loss: 1.4163 - val_accuracy: 0.7272\n",
            "Epoch 45/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1129 - accuracy: 0.9621 - val_loss: 1.2284 - val_accuracy: 0.7522\n",
            "Epoch 46/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.0950 - accuracy: 0.9671 - val_loss: 1.3325 - val_accuracy: 0.7584\n",
            "Epoch 47/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.1004 - accuracy: 0.9665 - val_loss: 1.1794 - val_accuracy: 0.7560\n",
            "Epoch 48/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.0968 - accuracy: 0.9668 - val_loss: 1.2405 - val_accuracy: 0.7696\n",
            "Epoch 49/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.0938 - accuracy: 0.9675 - val_loss: 1.2162 - val_accuracy: 0.7700\n",
            "Epoch 50/50\n",
            "44/44 [==============================] - 6s 139ms/step - loss: 0.0861 - accuracy: 0.9702 - val_loss: 1.1622 - val_accuracy: 0.7658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training and validation performance\n",
        "f,ax=plt.subplots(2,1) \n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[0].plot(history_2.history['loss'], color='b',label='Training Loss')\n",
        "ax[0].plot(history_2.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[1].plot(history_2.history['accuracy'],color='b',label='Training Accuracy')\n",
        "ax[1].plot(history_2.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "zE0N62l2A7z5",
        "outputId": "4855d456-aafd-4e29-edcb-cc1a63f2f3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f744c6b0940>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc_2 = model_2.evaluate(X_test_norm, y_test, verbose = 0)\n",
        "acc_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzCBP852BGq7",
        "outputId": "6dc9e7c3-5dae-469d-c9c0-4d4b371e6c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7731999754905701"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save('model_2.h5')"
      ],
      "metadata": {
        "id": "VeGyeYb_CMYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model 3: Model 1 + drop_out(0.2) after each maxpool + last dense layer, epoch = 100"
      ],
      "metadata": {
        "id": "cKgJjILwD6Bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Things to improve:\n",
        "+ Try with other dropout rate"
      ],
      "metadata": {
        "id": "wdPeT8x6GAVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=X_train_norm[0].shape)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_3 = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMhruJ6FD-pE",
        "outputId": "347ec9b5-a57a-41e1-f1a7-3f05aff2cb2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_28 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,397,226\n",
            "Trainable params: 2,396,330\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, # Define loss function\n",
        "                optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy']) # Define initial learning rate and metrics.\n",
        "\n",
        "# Train the model. Using Colab for training\n",
        "history_3 = model_3.fit(X_train_norm, y_train, # Data feature and data label\n",
        "                    batch_size=1024, # Batch size\n",
        "                    epochs=100, # Number of training epochs\n",
        "                    validation_data=(X_val_norm, y_val)) # Validation set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EklSInplEVB3",
        "outputId": "be5998d3-e330-42ed-cb0b-d95da0f45c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "44/44 [==============================] - 6s 116ms/step - loss: 2.9153 - accuracy: 0.3084 - val_loss: 2.5851 - val_accuracy: 0.0982\n",
            "Epoch 2/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 1.4714 - accuracy: 0.4656 - val_loss: 2.8798 - val_accuracy: 0.1092\n",
            "Epoch 3/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 1.2762 - accuracy: 0.5413 - val_loss: 3.5612 - val_accuracy: 0.1060\n",
            "Epoch 4/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 1.1315 - accuracy: 0.5952 - val_loss: 4.1691 - val_accuracy: 0.1498\n",
            "Epoch 5/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.9955 - accuracy: 0.6478 - val_loss: 4.7837 - val_accuracy: 0.1054\n",
            "Epoch 6/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.8811 - accuracy: 0.6862 - val_loss: 5.0777 - val_accuracy: 0.1606\n",
            "Epoch 7/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.7834 - accuracy: 0.7239 - val_loss: 4.6793 - val_accuracy: 0.1834\n",
            "Epoch 8/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.7032 - accuracy: 0.7518 - val_loss: 4.4425 - val_accuracy: 0.2056\n",
            "Epoch 9/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.6374 - accuracy: 0.7761 - val_loss: 3.6609 - val_accuracy: 0.2532\n",
            "Epoch 10/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5828 - accuracy: 0.7944 - val_loss: 3.2737 - val_accuracy: 0.2776\n",
            "Epoch 11/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.5171 - accuracy: 0.8154 - val_loss: 2.6625 - val_accuracy: 0.3608\n",
            "Epoch 12/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.4843 - accuracy: 0.8295 - val_loss: 1.6085 - val_accuracy: 0.5294\n",
            "Epoch 13/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.4389 - accuracy: 0.8442 - val_loss: 0.9829 - val_accuracy: 0.6766\n",
            "Epoch 14/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3956 - accuracy: 0.8596 - val_loss: 0.9170 - val_accuracy: 0.7106\n",
            "Epoch 15/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3631 - accuracy: 0.8700 - val_loss: 0.7033 - val_accuracy: 0.7742\n",
            "Epoch 16/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3214 - accuracy: 0.8879 - val_loss: 0.7270 - val_accuracy: 0.7622\n",
            "Epoch 17/100\n",
            "44/44 [==============================] - 5s 108ms/step - loss: 0.2965 - accuracy: 0.8944 - val_loss: 0.6433 - val_accuracy: 0.7918\n",
            "Epoch 18/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2686 - accuracy: 0.9043 - val_loss: 0.6605 - val_accuracy: 0.7916\n",
            "Epoch 19/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2415 - accuracy: 0.9138 - val_loss: 0.7413 - val_accuracy: 0.7830\n",
            "Epoch 20/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2121 - accuracy: 0.9257 - val_loss: 0.6689 - val_accuracy: 0.8002\n",
            "Epoch 21/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1955 - accuracy: 0.9304 - val_loss: 0.6714 - val_accuracy: 0.8034\n",
            "Epoch 22/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1755 - accuracy: 0.9379 - val_loss: 0.6662 - val_accuracy: 0.8126\n",
            "Epoch 23/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1580 - accuracy: 0.9447 - val_loss: 0.6573 - val_accuracy: 0.8100\n",
            "Epoch 24/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1419 - accuracy: 0.9506 - val_loss: 0.7165 - val_accuracy: 0.8034\n",
            "Epoch 25/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1349 - accuracy: 0.9525 - val_loss: 0.6745 - val_accuracy: 0.8144\n",
            "Epoch 26/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1211 - accuracy: 0.9584 - val_loss: 0.6904 - val_accuracy: 0.8140\n",
            "Epoch 27/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1139 - accuracy: 0.9606 - val_loss: 0.6608 - val_accuracy: 0.8186\n",
            "Epoch 28/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1063 - accuracy: 0.9633 - val_loss: 0.7487 - val_accuracy: 0.7984\n",
            "Epoch 29/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0993 - accuracy: 0.9663 - val_loss: 0.7046 - val_accuracy: 0.8106\n",
            "Epoch 30/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0917 - accuracy: 0.9679 - val_loss: 0.6960 - val_accuracy: 0.8188\n",
            "Epoch 31/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0857 - accuracy: 0.9712 - val_loss: 0.6927 - val_accuracy: 0.8164\n",
            "Epoch 32/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0831 - accuracy: 0.9717 - val_loss: 0.7302 - val_accuracy: 0.8080\n",
            "Epoch 33/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0767 - accuracy: 0.9743 - val_loss: 0.7125 - val_accuracy: 0.8150\n",
            "Epoch 34/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0737 - accuracy: 0.9740 - val_loss: 0.7862 - val_accuracy: 0.8062\n",
            "Epoch 35/100\n",
            "44/44 [==============================] - 5s 108ms/step - loss: 0.0692 - accuracy: 0.9771 - val_loss: 0.7329 - val_accuracy: 0.8114\n",
            "Epoch 36/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0659 - accuracy: 0.9772 - val_loss: 0.7778 - val_accuracy: 0.8152\n",
            "Epoch 37/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.7807 - val_accuracy: 0.8042\n",
            "Epoch 38/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0623 - accuracy: 0.9790 - val_loss: 0.7404 - val_accuracy: 0.8204\n",
            "Epoch 39/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0591 - accuracy: 0.9794 - val_loss: 0.8272 - val_accuracy: 0.8052\n",
            "Epoch 40/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0577 - accuracy: 0.9804 - val_loss: 0.7291 - val_accuracy: 0.8188\n",
            "Epoch 41/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0566 - accuracy: 0.9801 - val_loss: 0.7898 - val_accuracy: 0.8128\n",
            "Epoch 42/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.7617 - val_accuracy: 0.8220\n",
            "Epoch 43/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0527 - accuracy: 0.9818 - val_loss: 0.7953 - val_accuracy: 0.8120\n",
            "Epoch 44/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0481 - accuracy: 0.9838 - val_loss: 0.7821 - val_accuracy: 0.8162\n",
            "Epoch 45/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0505 - accuracy: 0.9832 - val_loss: 0.8740 - val_accuracy: 0.8054\n",
            "Epoch 46/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0493 - accuracy: 0.9826 - val_loss: 0.9693 - val_accuracy: 0.7948\n",
            "Epoch 47/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0502 - accuracy: 0.9823 - val_loss: 0.8266 - val_accuracy: 0.8142\n",
            "Epoch 48/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.0525 - accuracy: 0.9824 - val_loss: 0.8330 - val_accuracy: 0.8044\n",
            "Epoch 49/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0464 - accuracy: 0.9844 - val_loss: 0.7883 - val_accuracy: 0.8228\n",
            "Epoch 50/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0454 - accuracy: 0.9848 - val_loss: 0.7456 - val_accuracy: 0.8206\n",
            "Epoch 51/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0428 - accuracy: 0.9850 - val_loss: 0.8293 - val_accuracy: 0.8166\n",
            "Epoch 52/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0423 - accuracy: 0.9853 - val_loss: 0.7874 - val_accuracy: 0.8214\n",
            "Epoch 53/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0431 - accuracy: 0.9854 - val_loss: 0.7933 - val_accuracy: 0.8300\n",
            "Epoch 54/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 0.8528 - val_accuracy: 0.8170\n",
            "Epoch 55/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0409 - accuracy: 0.9858 - val_loss: 0.7966 - val_accuracy: 0.8262\n",
            "Epoch 56/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.8947 - val_accuracy: 0.8124\n",
            "Epoch 57/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0440 - accuracy: 0.9852 - val_loss: 0.8373 - val_accuracy: 0.8158\n",
            "Epoch 58/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0422 - accuracy: 0.9854 - val_loss: 1.0146 - val_accuracy: 0.8004\n",
            "Epoch 59/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0422 - accuracy: 0.9856 - val_loss: 0.8615 - val_accuracy: 0.8096\n",
            "Epoch 60/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0420 - accuracy: 0.9852 - val_loss: 0.8403 - val_accuracy: 0.8062\n",
            "Epoch 61/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0388 - accuracy: 0.9862 - val_loss: 0.8264 - val_accuracy: 0.8182\n",
            "Epoch 62/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0374 - accuracy: 0.9871 - val_loss: 0.8129 - val_accuracy: 0.8232\n",
            "Epoch 63/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0419 - accuracy: 0.9859 - val_loss: 0.8208 - val_accuracy: 0.8190\n",
            "Epoch 64/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0374 - accuracy: 0.9870 - val_loss: 0.9430 - val_accuracy: 0.8098\n",
            "Epoch 65/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0358 - accuracy: 0.9880 - val_loss: 0.8236 - val_accuracy: 0.8200\n",
            "Epoch 66/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0377 - accuracy: 0.9874 - val_loss: 0.9738 - val_accuracy: 0.8026\n",
            "Epoch 67/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0373 - accuracy: 0.9870 - val_loss: 0.9071 - val_accuracy: 0.8214\n",
            "Epoch 68/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.8573 - val_accuracy: 0.8154\n",
            "Epoch 69/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 0.8666 - val_accuracy: 0.8222\n",
            "Epoch 70/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0364 - accuracy: 0.9873 - val_loss: 0.8728 - val_accuracy: 0.8232\n",
            "Epoch 71/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0372 - accuracy: 0.9871 - val_loss: 0.8247 - val_accuracy: 0.8250\n",
            "Epoch 72/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0355 - accuracy: 0.9876 - val_loss: 0.8681 - val_accuracy: 0.8200\n",
            "Epoch 73/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.8790 - val_accuracy: 0.8212\n",
            "Epoch 74/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0299 - accuracy: 0.9890 - val_loss: 0.8695 - val_accuracy: 0.8314\n",
            "Epoch 75/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.8751 - val_accuracy: 0.8246\n",
            "Epoch 76/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.8857 - val_accuracy: 0.8182\n",
            "Epoch 77/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0361 - accuracy: 0.9883 - val_loss: 0.8898 - val_accuracy: 0.8144\n",
            "Epoch 78/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.0342 - accuracy: 0.9878 - val_loss: 0.8879 - val_accuracy: 0.8230\n",
            "Epoch 79/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0325 - accuracy: 0.9884 - val_loss: 0.8663 - val_accuracy: 0.8280\n",
            "Epoch 80/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 0.9705 - val_accuracy: 0.8160\n",
            "Epoch 81/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0326 - accuracy: 0.9894 - val_loss: 0.9602 - val_accuracy: 0.8146\n",
            "Epoch 82/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0332 - accuracy: 0.9883 - val_loss: 0.8972 - val_accuracy: 0.8254\n",
            "Epoch 83/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 0.8822 - val_accuracy: 0.8258\n",
            "Epoch 84/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.8902 - val_accuracy: 0.8206\n",
            "Epoch 85/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0282 - accuracy: 0.9898 - val_loss: 0.9815 - val_accuracy: 0.8124\n",
            "Epoch 86/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0289 - accuracy: 0.9903 - val_loss: 1.0120 - val_accuracy: 0.8114\n",
            "Epoch 87/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 0.9738 - val_accuracy: 0.8138\n",
            "Epoch 88/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 1.0017 - val_accuracy: 0.8064\n",
            "Epoch 89/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0315 - accuracy: 0.9890 - val_loss: 1.0158 - val_accuracy: 0.8150\n",
            "Epoch 90/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0331 - accuracy: 0.9888 - val_loss: 0.9084 - val_accuracy: 0.8244\n",
            "Epoch 91/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.9453 - val_accuracy: 0.8204\n",
            "Epoch 92/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0333 - accuracy: 0.9885 - val_loss: 1.0056 - val_accuracy: 0.8202\n",
            "Epoch 93/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0338 - accuracy: 0.9882 - val_loss: 0.9836 - val_accuracy: 0.8162\n",
            "Epoch 94/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0311 - accuracy: 0.9895 - val_loss: 0.9855 - val_accuracy: 0.8224\n",
            "Epoch 95/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.9359 - val_accuracy: 0.8220\n",
            "Epoch 96/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 0.9955 - val_accuracy: 0.8212\n",
            "Epoch 97/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0337 - accuracy: 0.9886 - val_loss: 0.9747 - val_accuracy: 0.8156\n",
            "Epoch 98/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.9850 - val_accuracy: 0.8186\n",
            "Epoch 99/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.0266 - accuracy: 0.9906 - val_loss: 0.9474 - val_accuracy: 0.8284\n",
            "Epoch 100/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.0275 - accuracy: 0.9910 - val_loss: 1.0214 - val_accuracy: 0.8186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training and validation performance\n",
        "f,ax=plt.subplots(2,1) \n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[0].plot(history_3.history['loss'], color='b',label='Training Loss')\n",
        "ax[0].plot(history_3.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[1].plot(history_3.history['accuracy'],color='b',label='Training Accuracy')\n",
        "ax[1].plot(history_3.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "doRxsF3YFp9j",
        "outputId": "e36a59c3-2791-45e6-ccf4-6d6ab8eec14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f740207f610>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc_3 = model_3.evaluate(X_test_norm, y_test, verbose = 0)\n",
        "acc_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_oyxckHFxrm",
        "outputId": "9e250ae0-3cdc-4b45-d514-a2a7da64ccb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8202999830245972"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.save('model_3.h5')"
      ],
      "metadata": {
        "id": "ckzj8m2WJWJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Model 1 + dropout(0.5) after each maxpool and (0.2) before last dense layer, epoch = 100\n"
      ],
      "metadata": {
        "id": "dF56TkrOLFHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=X_train_norm[0].shape)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_4 = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqD9gi4QLKoR",
        "outputId": "c695d4a2-a474-4dfc-cbc4-ec4bba2fa822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_36 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_37 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_38 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_39 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,397,226\n",
            "Trainable params: 2,396,330\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_4.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, # Define loss function\n",
        "                optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy']) # Define initial learning rate and metrics.\n",
        "\n",
        "# Train the model. Using Colab for training\n",
        "history_4 = model_4.fit(X_train_norm, y_train, # Data feature and data label\n",
        "                    batch_size=1024, # Batch size\n",
        "                    epochs=100, # Number of training epochs\n",
        "                    validation_data=(X_val_norm, y_val)) # Validation set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKPk6rYYLaPB",
        "outputId": "c9798754-c3d7-4ec0-9e58-c8ef9ee4cb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "44/44 [==============================] - 6s 124ms/step - loss: 3.3815 - accuracy: 0.2488 - val_loss: 2.3734 - val_accuracy: 0.0960\n",
            "Epoch 2/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 1.6542 - accuracy: 0.3960 - val_loss: 2.6086 - val_accuracy: 0.1132\n",
            "Epoch 3/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 1.4881 - accuracy: 0.4613 - val_loss: 2.9469 - val_accuracy: 0.1238\n",
            "Epoch 4/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 1.3635 - accuracy: 0.5067 - val_loss: 3.1921 - val_accuracy: 0.1898\n",
            "Epoch 5/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 1.2645 - accuracy: 0.5443 - val_loss: 4.2663 - val_accuracy: 0.1442\n",
            "Epoch 6/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 1.1743 - accuracy: 0.5764 - val_loss: 4.9666 - val_accuracy: 0.1086\n",
            "Epoch 7/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 1.0893 - accuracy: 0.6076 - val_loss: 4.0914 - val_accuracy: 0.1860\n",
            "Epoch 8/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 1.0225 - accuracy: 0.6356 - val_loss: 4.0730 - val_accuracy: 0.1524\n",
            "Epoch 9/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.9646 - accuracy: 0.6543 - val_loss: 3.6660 - val_accuracy: 0.2244\n",
            "Epoch 10/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.9165 - accuracy: 0.6723 - val_loss: 3.1234 - val_accuracy: 0.2440\n",
            "Epoch 11/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.8683 - accuracy: 0.6918 - val_loss: 2.1481 - val_accuracy: 0.3700\n",
            "Epoch 12/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.8235 - accuracy: 0.7026 - val_loss: 1.4598 - val_accuracy: 0.5064\n",
            "Epoch 13/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.7862 - accuracy: 0.7209 - val_loss: 1.0395 - val_accuracy: 0.6232\n",
            "Epoch 14/100\n",
            "44/44 [==============================] - 5s 108ms/step - loss: 0.7491 - accuracy: 0.7338 - val_loss: 0.9045 - val_accuracy: 0.6840\n",
            "Epoch 15/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.7178 - accuracy: 0.7449 - val_loss: 0.7839 - val_accuracy: 0.7136\n",
            "Epoch 16/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.6889 - accuracy: 0.7559 - val_loss: 0.6903 - val_accuracy: 0.7518\n",
            "Epoch 17/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.6568 - accuracy: 0.7658 - val_loss: 0.6525 - val_accuracy: 0.7624\n",
            "Epoch 18/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.6350 - accuracy: 0.7744 - val_loss: 0.7043 - val_accuracy: 0.7506\n",
            "Epoch 19/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.6183 - accuracy: 0.7792 - val_loss: 0.7237 - val_accuracy: 0.7464\n",
            "Epoch 20/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5966 - accuracy: 0.7889 - val_loss: 0.6705 - val_accuracy: 0.7662\n",
            "Epoch 21/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5715 - accuracy: 0.7959 - val_loss: 0.6335 - val_accuracy: 0.7798\n",
            "Epoch 22/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5526 - accuracy: 0.8050 - val_loss: 0.6979 - val_accuracy: 0.7606\n",
            "Epoch 23/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.5382 - accuracy: 0.8089 - val_loss: 0.6311 - val_accuracy: 0.7766\n",
            "Epoch 24/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5188 - accuracy: 0.8146 - val_loss: 0.6933 - val_accuracy: 0.7646\n",
            "Epoch 25/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5033 - accuracy: 0.8215 - val_loss: 0.5780 - val_accuracy: 0.7938\n",
            "Epoch 26/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4842 - accuracy: 0.8259 - val_loss: 0.5654 - val_accuracy: 0.8026\n",
            "Epoch 27/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.4706 - accuracy: 0.8307 - val_loss: 0.6037 - val_accuracy: 0.7910\n",
            "Epoch 28/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.4589 - accuracy: 0.8368 - val_loss: 0.5859 - val_accuracy: 0.7992\n",
            "Epoch 29/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4468 - accuracy: 0.8394 - val_loss: 0.5981 - val_accuracy: 0.7926\n",
            "Epoch 30/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4331 - accuracy: 0.8459 - val_loss: 0.7341 - val_accuracy: 0.7552\n",
            "Epoch 31/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4196 - accuracy: 0.8514 - val_loss: 0.5806 - val_accuracy: 0.8032\n",
            "Epoch 32/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.4049 - accuracy: 0.8574 - val_loss: 0.5639 - val_accuracy: 0.8116\n",
            "Epoch 33/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3954 - accuracy: 0.8581 - val_loss: 0.7167 - val_accuracy: 0.7628\n",
            "Epoch 34/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3867 - accuracy: 0.8637 - val_loss: 0.5401 - val_accuracy: 0.8104\n",
            "Epoch 35/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3757 - accuracy: 0.8657 - val_loss: 0.5699 - val_accuracy: 0.8080\n",
            "Epoch 36/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3598 - accuracy: 0.8715 - val_loss: 0.5881 - val_accuracy: 0.8078\n",
            "Epoch 37/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3510 - accuracy: 0.8751 - val_loss: 0.5145 - val_accuracy: 0.8272\n",
            "Epoch 38/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.3453 - accuracy: 0.8760 - val_loss: 0.5173 - val_accuracy: 0.8256\n",
            "Epoch 39/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3435 - accuracy: 0.8773 - val_loss: 0.5660 - val_accuracy: 0.8046\n",
            "Epoch 40/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3293 - accuracy: 0.8826 - val_loss: 0.5676 - val_accuracy: 0.8112\n",
            "Epoch 41/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3166 - accuracy: 0.8863 - val_loss: 0.5276 - val_accuracy: 0.8220\n",
            "Epoch 42/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3119 - accuracy: 0.8888 - val_loss: 0.5501 - val_accuracy: 0.8134\n",
            "Epoch 43/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.3075 - accuracy: 0.8894 - val_loss: 0.5445 - val_accuracy: 0.8152\n",
            "Epoch 44/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2932 - accuracy: 0.8966 - val_loss: 0.5288 - val_accuracy: 0.8214\n",
            "Epoch 45/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2862 - accuracy: 0.8970 - val_loss: 0.5328 - val_accuracy: 0.8242\n",
            "Epoch 46/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2739 - accuracy: 0.9014 - val_loss: 0.5780 - val_accuracy: 0.8094\n",
            "Epoch 47/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2743 - accuracy: 0.9016 - val_loss: 0.5552 - val_accuracy: 0.8162\n",
            "Epoch 48/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2590 - accuracy: 0.9079 - val_loss: 0.5991 - val_accuracy: 0.8094\n",
            "Epoch 49/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2582 - accuracy: 0.9066 - val_loss: 0.5849 - val_accuracy: 0.8172\n",
            "Epoch 50/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2530 - accuracy: 0.9105 - val_loss: 0.5500 - val_accuracy: 0.8230\n",
            "Epoch 51/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2481 - accuracy: 0.9099 - val_loss: 0.5346 - val_accuracy: 0.8250\n",
            "Epoch 52/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2428 - accuracy: 0.9133 - val_loss: 0.5676 - val_accuracy: 0.8152\n",
            "Epoch 53/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2381 - accuracy: 0.9155 - val_loss: 0.5574 - val_accuracy: 0.8218\n",
            "Epoch 54/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2292 - accuracy: 0.9186 - val_loss: 0.5345 - val_accuracy: 0.8270\n",
            "Epoch 55/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2268 - accuracy: 0.9190 - val_loss: 0.5387 - val_accuracy: 0.8334\n",
            "Epoch 56/100\n",
            "44/44 [==============================] - 5s 112ms/step - loss: 0.2210 - accuracy: 0.9218 - val_loss: 0.5596 - val_accuracy: 0.8252\n",
            "Epoch 57/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2137 - accuracy: 0.9241 - val_loss: 0.5762 - val_accuracy: 0.8210\n",
            "Epoch 58/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2070 - accuracy: 0.9251 - val_loss: 0.5378 - val_accuracy: 0.8302\n",
            "Epoch 59/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.2004 - accuracy: 0.9292 - val_loss: 0.5375 - val_accuracy: 0.8320\n",
            "Epoch 60/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2050 - accuracy: 0.9272 - val_loss: 0.5517 - val_accuracy: 0.8232\n",
            "Epoch 61/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1963 - accuracy: 0.9307 - val_loss: 0.6690 - val_accuracy: 0.8010\n",
            "Epoch 62/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1936 - accuracy: 0.9314 - val_loss: 0.6017 - val_accuracy: 0.8222\n",
            "Epoch 63/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1949 - accuracy: 0.9311 - val_loss: 0.5696 - val_accuracy: 0.8260\n",
            "Epoch 64/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1847 - accuracy: 0.9352 - val_loss: 0.5621 - val_accuracy: 0.8254\n",
            "Epoch 65/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1894 - accuracy: 0.9333 - val_loss: 0.5223 - val_accuracy: 0.8340\n",
            "Epoch 66/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1789 - accuracy: 0.9360 - val_loss: 0.5667 - val_accuracy: 0.8268\n",
            "Epoch 67/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1784 - accuracy: 0.9362 - val_loss: 0.5421 - val_accuracy: 0.8306\n",
            "Epoch 68/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1784 - accuracy: 0.9367 - val_loss: 0.5458 - val_accuracy: 0.8302\n",
            "Epoch 69/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1739 - accuracy: 0.9390 - val_loss: 0.5749 - val_accuracy: 0.8218\n",
            "Epoch 70/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1709 - accuracy: 0.9399 - val_loss: 0.5784 - val_accuracy: 0.8252\n",
            "Epoch 71/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1658 - accuracy: 0.9397 - val_loss: 0.5459 - val_accuracy: 0.8320\n",
            "Epoch 72/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1698 - accuracy: 0.9388 - val_loss: 0.5934 - val_accuracy: 0.8194\n",
            "Epoch 73/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1597 - accuracy: 0.9432 - val_loss: 0.5805 - val_accuracy: 0.8232\n",
            "Epoch 74/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1582 - accuracy: 0.9439 - val_loss: 0.5642 - val_accuracy: 0.8360\n",
            "Epoch 75/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1572 - accuracy: 0.9444 - val_loss: 0.6161 - val_accuracy: 0.8230\n",
            "Epoch 76/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1569 - accuracy: 0.9448 - val_loss: 0.5673 - val_accuracy: 0.8344\n",
            "Epoch 77/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1541 - accuracy: 0.9463 - val_loss: 0.5690 - val_accuracy: 0.8352\n",
            "Epoch 78/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1559 - accuracy: 0.9454 - val_loss: 0.5602 - val_accuracy: 0.8312\n",
            "Epoch 79/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1503 - accuracy: 0.9473 - val_loss: 0.6139 - val_accuracy: 0.8140\n",
            "Epoch 80/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1474 - accuracy: 0.9484 - val_loss: 0.5439 - val_accuracy: 0.8356\n",
            "Epoch 81/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1439 - accuracy: 0.9492 - val_loss: 0.5946 - val_accuracy: 0.8248\n",
            "Epoch 82/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1431 - accuracy: 0.9507 - val_loss: 0.5822 - val_accuracy: 0.8390\n",
            "Epoch 83/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1432 - accuracy: 0.9502 - val_loss: 0.5608 - val_accuracy: 0.8308\n",
            "Epoch 84/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1398 - accuracy: 0.9510 - val_loss: 0.5701 - val_accuracy: 0.8326\n",
            "Epoch 85/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1398 - accuracy: 0.9501 - val_loss: 0.6246 - val_accuracy: 0.8198\n",
            "Epoch 86/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.1370 - accuracy: 0.9516 - val_loss: 0.6565 - val_accuracy: 0.8150\n",
            "Epoch 87/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1347 - accuracy: 0.9530 - val_loss: 0.5791 - val_accuracy: 0.8328\n",
            "Epoch 88/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1354 - accuracy: 0.9525 - val_loss: 0.5564 - val_accuracy: 0.8352\n",
            "Epoch 89/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1322 - accuracy: 0.9545 - val_loss: 0.5741 - val_accuracy: 0.8382\n",
            "Epoch 90/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1333 - accuracy: 0.9539 - val_loss: 0.5624 - val_accuracy: 0.8334\n",
            "Epoch 91/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1284 - accuracy: 0.9562 - val_loss: 0.6247 - val_accuracy: 0.8214\n",
            "Epoch 92/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1281 - accuracy: 0.9562 - val_loss: 0.5533 - val_accuracy: 0.8390\n",
            "Epoch 93/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1316 - accuracy: 0.9541 - val_loss: 0.5970 - val_accuracy: 0.8296\n",
            "Epoch 94/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1268 - accuracy: 0.9552 - val_loss: 0.5808 - val_accuracy: 0.8342\n",
            "Epoch 95/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1253 - accuracy: 0.9570 - val_loss: 0.6134 - val_accuracy: 0.8318\n",
            "Epoch 96/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1220 - accuracy: 0.9577 - val_loss: 0.6407 - val_accuracy: 0.8242\n",
            "Epoch 97/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1236 - accuracy: 0.9568 - val_loss: 0.5930 - val_accuracy: 0.8386\n",
            "Epoch 98/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1217 - accuracy: 0.9570 - val_loss: 0.6045 - val_accuracy: 0.8302\n",
            "Epoch 99/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1221 - accuracy: 0.9566 - val_loss: 0.6171 - val_accuracy: 0.8276\n",
            "Epoch 100/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1194 - accuracy: 0.9581 - val_loss: 0.5834 - val_accuracy: 0.8374\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training and validation performance\n",
        "f,ax=plt.subplots(2,1) \n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[0].plot(history_4.history['loss'], color='b',label='Training Loss')\n",
        "ax[0].plot(history_4.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[1].plot(history_4.history['accuracy'],color='b',label='Training Accuracy')\n",
        "ax[1].plot(history_4.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "NeRUPiCeNw-n",
        "outputId": "1a35c2d9-70c0-4f91-87d9-b315db2274d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7436506100>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc_4 = model_4.evaluate(X_test_norm, y_test, verbose = 0)\n",
        "acc_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEJWwbDHN3zS",
        "outputId": "a0c4bf33-dbff-49a3-ea9b-d77076bc957e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8348000049591064"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.save('model_4.h5')"
      ],
      "metadata": {
        "id": "vwzF4XrwOBLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Model 1 + increasing dropout rate after each maxpool and dropout(0.2) before 2 dense layers, epoch = 100"
      ],
      "metadata": {
        "id": "U4sq4Vg2OA7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model using the functional API\n",
        "# input layer\n",
        "i = Input(shape=X_train_norm[0].shape)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# Hidden layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "# last hidden layer i.e.. output layer\n",
        "x = Dense(10, activation='softmax')(x)\n",
        "\n",
        "model_5 = Model(i, x)\n",
        "\n",
        "# model description\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOl5BfEZO4iz",
        "outputId": "f1985473-a130-448f-984c-d503eb1ac755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_40 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_45 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,397,226\n",
            "Trainable params: 2,396,330\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_5.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, # Define loss function\n",
        "                optimizer= tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['accuracy']) # Define initial learning rate and metrics.\n",
        "\n",
        "# Train the model. Using Colab for training\n",
        "history_5 = model_5.fit(X_train_norm, y_train, # Data feature and data label\n",
        "                    batch_size=1024, # Batch size\n",
        "                    epochs=100, # Number of training epochs\n",
        "                    validation_data=(X_val_norm, y_val)) # Validation set"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_HXK-hnPic8",
        "outputId": "bea47c28-5dd4-40ed-ea34-56a453b2f102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "44/44 [==============================] - 6s 117ms/step - loss: 3.2354 - accuracy: 0.2661 - val_loss: 2.2678 - val_accuracy: 0.1530\n",
            "Epoch 2/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 1.6084 - accuracy: 0.4158 - val_loss: 3.2087 - val_accuracy: 0.1368\n",
            "Epoch 3/100\n",
            "44/44 [==============================] - 5s 112ms/step - loss: 1.4121 - accuracy: 0.4874 - val_loss: 4.1046 - val_accuracy: 0.0960\n",
            "Epoch 4/100\n",
            "44/44 [==============================] - 5s 112ms/step - loss: 1.2909 - accuracy: 0.5326 - val_loss: 4.6703 - val_accuracy: 0.0960\n",
            "Epoch 5/100\n",
            "44/44 [==============================] - 5s 112ms/step - loss: 1.1895 - accuracy: 0.5726 - val_loss: 4.0212 - val_accuracy: 0.1544\n",
            "Epoch 6/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 1.0996 - accuracy: 0.6074 - val_loss: 3.6172 - val_accuracy: 0.1920\n",
            "Epoch 7/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 1.0326 - accuracy: 0.6308 - val_loss: 3.2545 - val_accuracy: 0.2280\n",
            "Epoch 8/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.9696 - accuracy: 0.6511 - val_loss: 2.5373 - val_accuracy: 0.3288\n",
            "Epoch 9/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.9110 - accuracy: 0.6741 - val_loss: 1.9861 - val_accuracy: 0.3890\n",
            "Epoch 10/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.8658 - accuracy: 0.6918 - val_loss: 1.7422 - val_accuracy: 0.4388\n",
            "Epoch 11/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.8141 - accuracy: 0.7079 - val_loss: 1.4274 - val_accuracy: 0.5152\n",
            "Epoch 12/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.7729 - accuracy: 0.7240 - val_loss: 1.2417 - val_accuracy: 0.5678\n",
            "Epoch 13/100\n",
            "44/44 [==============================] - 5s 113ms/step - loss: 0.7323 - accuracy: 0.7382 - val_loss: 0.8866 - val_accuracy: 0.6862\n",
            "Epoch 14/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.7021 - accuracy: 0.7503 - val_loss: 0.7915 - val_accuracy: 0.7172\n",
            "Epoch 15/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.6654 - accuracy: 0.7612 - val_loss: 0.8328 - val_accuracy: 0.7010\n",
            "Epoch 16/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.6412 - accuracy: 0.7723 - val_loss: 0.7055 - val_accuracy: 0.7520\n",
            "Epoch 17/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.6088 - accuracy: 0.7835 - val_loss: 0.6976 - val_accuracy: 0.7496\n",
            "Epoch 18/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5841 - accuracy: 0.7919 - val_loss: 0.6708 - val_accuracy: 0.7578\n",
            "Epoch 19/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5627 - accuracy: 0.8003 - val_loss: 0.6166 - val_accuracy: 0.7770\n",
            "Epoch 20/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5338 - accuracy: 0.8092 - val_loss: 0.6171 - val_accuracy: 0.7780\n",
            "Epoch 21/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5191 - accuracy: 0.8120 - val_loss: 0.6371 - val_accuracy: 0.7748\n",
            "Epoch 22/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.5052 - accuracy: 0.8200 - val_loss: 0.6136 - val_accuracy: 0.7818\n",
            "Epoch 23/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4782 - accuracy: 0.8271 - val_loss: 0.5795 - val_accuracy: 0.7954\n",
            "Epoch 24/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4650 - accuracy: 0.8357 - val_loss: 0.5656 - val_accuracy: 0.7998\n",
            "Epoch 25/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4401 - accuracy: 0.8443 - val_loss: 0.5576 - val_accuracy: 0.8056\n",
            "Epoch 26/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4333 - accuracy: 0.8453 - val_loss: 0.5627 - val_accuracy: 0.8030\n",
            "Epoch 27/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4144 - accuracy: 0.8504 - val_loss: 0.5827 - val_accuracy: 0.7984\n",
            "Epoch 28/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.4059 - accuracy: 0.8547 - val_loss: 0.5419 - val_accuracy: 0.8104\n",
            "Epoch 29/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3871 - accuracy: 0.8613 - val_loss: 0.5579 - val_accuracy: 0.8050\n",
            "Epoch 30/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3755 - accuracy: 0.8650 - val_loss: 0.5377 - val_accuracy: 0.8180\n",
            "Epoch 31/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3670 - accuracy: 0.8686 - val_loss: 0.5285 - val_accuracy: 0.8194\n",
            "Epoch 32/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3560 - accuracy: 0.8726 - val_loss: 0.5986 - val_accuracy: 0.7952\n",
            "Epoch 33/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3343 - accuracy: 0.8791 - val_loss: 0.5764 - val_accuracy: 0.8054\n",
            "Epoch 34/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.3282 - accuracy: 0.8825 - val_loss: 0.5327 - val_accuracy: 0.8180\n",
            "Epoch 35/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3151 - accuracy: 0.8858 - val_loss: 0.5603 - val_accuracy: 0.8168\n",
            "Epoch 36/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3070 - accuracy: 0.8900 - val_loss: 0.5208 - val_accuracy: 0.8260\n",
            "Epoch 37/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.3036 - accuracy: 0.8908 - val_loss: 0.5589 - val_accuracy: 0.8168\n",
            "Epoch 38/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2888 - accuracy: 0.8954 - val_loss: 0.5369 - val_accuracy: 0.8246\n",
            "Epoch 39/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2878 - accuracy: 0.8972 - val_loss: 0.6674 - val_accuracy: 0.7850\n",
            "Epoch 40/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.2772 - accuracy: 0.9008 - val_loss: 0.5248 - val_accuracy: 0.8234\n",
            "Epoch 41/100\n",
            "44/44 [==============================] - 5s 112ms/step - loss: 0.2668 - accuracy: 0.9058 - val_loss: 0.6008 - val_accuracy: 0.8062\n",
            "Epoch 42/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2585 - accuracy: 0.9069 - val_loss: 0.5116 - val_accuracy: 0.8354\n",
            "Epoch 43/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2453 - accuracy: 0.9114 - val_loss: 0.5442 - val_accuracy: 0.8244\n",
            "Epoch 44/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2485 - accuracy: 0.9102 - val_loss: 0.5384 - val_accuracy: 0.8238\n",
            "Epoch 45/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2381 - accuracy: 0.9144 - val_loss: 0.5375 - val_accuracy: 0.8244\n",
            "Epoch 46/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2311 - accuracy: 0.9171 - val_loss: 0.5021 - val_accuracy: 0.8344\n",
            "Epoch 47/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2295 - accuracy: 0.9172 - val_loss: 0.5346 - val_accuracy: 0.8258\n",
            "Epoch 48/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2179 - accuracy: 0.9198 - val_loss: 0.6490 - val_accuracy: 0.8000\n",
            "Epoch 49/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2226 - accuracy: 0.9200 - val_loss: 0.5217 - val_accuracy: 0.8300\n",
            "Epoch 50/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2083 - accuracy: 0.9248 - val_loss: 0.5414 - val_accuracy: 0.8278\n",
            "Epoch 51/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2017 - accuracy: 0.9274 - val_loss: 0.5415 - val_accuracy: 0.8302\n",
            "Epoch 52/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.2021 - accuracy: 0.9266 - val_loss: 0.5236 - val_accuracy: 0.8318\n",
            "Epoch 53/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1936 - accuracy: 0.9303 - val_loss: 0.5131 - val_accuracy: 0.8422\n",
            "Epoch 54/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1883 - accuracy: 0.9345 - val_loss: 0.5090 - val_accuracy: 0.8412\n",
            "Epoch 55/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1843 - accuracy: 0.9341 - val_loss: 0.5260 - val_accuracy: 0.8302\n",
            "Epoch 56/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1852 - accuracy: 0.9326 - val_loss: 0.5372 - val_accuracy: 0.8288\n",
            "Epoch 57/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1807 - accuracy: 0.9356 - val_loss: 0.5120 - val_accuracy: 0.8368\n",
            "Epoch 58/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1707 - accuracy: 0.9388 - val_loss: 0.5883 - val_accuracy: 0.8224\n",
            "Epoch 59/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1675 - accuracy: 0.9396 - val_loss: 0.5185 - val_accuracy: 0.8384\n",
            "Epoch 60/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1698 - accuracy: 0.9403 - val_loss: 0.5685 - val_accuracy: 0.8346\n",
            "Epoch 61/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1595 - accuracy: 0.9431 - val_loss: 0.5454 - val_accuracy: 0.8346\n",
            "Epoch 62/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1654 - accuracy: 0.9401 - val_loss: 0.5752 - val_accuracy: 0.8352\n",
            "Epoch 63/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1592 - accuracy: 0.9436 - val_loss: 0.5083 - val_accuracy: 0.8442\n",
            "Epoch 64/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1639 - accuracy: 0.9434 - val_loss: 0.5558 - val_accuracy: 0.8256\n",
            "Epoch 65/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1557 - accuracy: 0.9443 - val_loss: 0.5363 - val_accuracy: 0.8390\n",
            "Epoch 66/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1502 - accuracy: 0.9472 - val_loss: 0.5341 - val_accuracy: 0.8358\n",
            "Epoch 67/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1469 - accuracy: 0.9477 - val_loss: 0.5283 - val_accuracy: 0.8362\n",
            "Epoch 68/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1516 - accuracy: 0.9473 - val_loss: 0.5072 - val_accuracy: 0.8430\n",
            "Epoch 69/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1531 - accuracy: 0.9455 - val_loss: 0.5136 - val_accuracy: 0.8396\n",
            "Epoch 70/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1435 - accuracy: 0.9497 - val_loss: 0.5304 - val_accuracy: 0.8452\n",
            "Epoch 71/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.1413 - accuracy: 0.9492 - val_loss: 0.5362 - val_accuracy: 0.8420\n",
            "Epoch 72/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1371 - accuracy: 0.9528 - val_loss: 0.5315 - val_accuracy: 0.8390\n",
            "Epoch 73/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1399 - accuracy: 0.9510 - val_loss: 0.5232 - val_accuracy: 0.8456\n",
            "Epoch 74/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1340 - accuracy: 0.9532 - val_loss: 0.5530 - val_accuracy: 0.8456\n",
            "Epoch 75/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1339 - accuracy: 0.9523 - val_loss: 0.6167 - val_accuracy: 0.8246\n",
            "Epoch 76/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1346 - accuracy: 0.9527 - val_loss: 0.5840 - val_accuracy: 0.8364\n",
            "Epoch 77/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1283 - accuracy: 0.9538 - val_loss: 0.5118 - val_accuracy: 0.8498\n",
            "Epoch 78/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1335 - accuracy: 0.9533 - val_loss: 0.5266 - val_accuracy: 0.8420\n",
            "Epoch 79/100\n",
            "44/44 [==============================] - 5s 111ms/step - loss: 0.1236 - accuracy: 0.9563 - val_loss: 0.5894 - val_accuracy: 0.8380\n",
            "Epoch 80/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1245 - accuracy: 0.9558 - val_loss: 0.5251 - val_accuracy: 0.8438\n",
            "Epoch 81/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1230 - accuracy: 0.9564 - val_loss: 0.5185 - val_accuracy: 0.8476\n",
            "Epoch 82/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1233 - accuracy: 0.9583 - val_loss: 0.5759 - val_accuracy: 0.8392\n",
            "Epoch 83/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1143 - accuracy: 0.9592 - val_loss: 0.5865 - val_accuracy: 0.8402\n",
            "Epoch 84/100\n",
            "44/44 [==============================] - 5s 109ms/step - loss: 0.1221 - accuracy: 0.9572 - val_loss: 0.5439 - val_accuracy: 0.8436\n",
            "Epoch 85/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1186 - accuracy: 0.9585 - val_loss: 0.5717 - val_accuracy: 0.8436\n",
            "Epoch 86/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1176 - accuracy: 0.9584 - val_loss: 0.5139 - val_accuracy: 0.8456\n",
            "Epoch 87/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1162 - accuracy: 0.9600 - val_loss: 0.5242 - val_accuracy: 0.8474\n",
            "Epoch 88/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1165 - accuracy: 0.9590 - val_loss: 0.5573 - val_accuracy: 0.8430\n",
            "Epoch 89/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1181 - accuracy: 0.9594 - val_loss: 0.5417 - val_accuracy: 0.8426\n",
            "Epoch 90/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1098 - accuracy: 0.9613 - val_loss: 0.5345 - val_accuracy: 0.8448\n",
            "Epoch 91/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1087 - accuracy: 0.9626 - val_loss: 0.5519 - val_accuracy: 0.8502\n",
            "Epoch 92/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1123 - accuracy: 0.9598 - val_loss: 0.5754 - val_accuracy: 0.8372\n",
            "Epoch 93/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1098 - accuracy: 0.9617 - val_loss: 0.5425 - val_accuracy: 0.8474\n",
            "Epoch 94/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1070 - accuracy: 0.9627 - val_loss: 0.5338 - val_accuracy: 0.8470\n",
            "Epoch 95/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1029 - accuracy: 0.9637 - val_loss: 0.5207 - val_accuracy: 0.8500\n",
            "Epoch 96/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1047 - accuracy: 0.9635 - val_loss: 0.5649 - val_accuracy: 0.8526\n",
            "Epoch 97/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1080 - accuracy: 0.9626 - val_loss: 0.5577 - val_accuracy: 0.8414\n",
            "Epoch 98/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1048 - accuracy: 0.9640 - val_loss: 0.5775 - val_accuracy: 0.8476\n",
            "Epoch 99/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1021 - accuracy: 0.9633 - val_loss: 0.5329 - val_accuracy: 0.8476\n",
            "Epoch 100/100\n",
            "44/44 [==============================] - 5s 110ms/step - loss: 0.1033 - accuracy: 0.9644 - val_loss: 0.5292 - val_accuracy: 0.8530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training and validation performance\n",
        "f,ax=plt.subplots(2,1) \n",
        "\n",
        "# Plot training and validation loss\n",
        "ax[0].plot(history_5.history['loss'], color='b',label='Training Loss')\n",
        "ax[0].plot(history_5.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax[1].plot(history_5.history['accuracy'],color='b',label='Training Accuracy')\n",
        "ax[1].plot(history_5.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "go0t19keRxcr",
        "outputId": "13214fd3-ca7d-48ec-b004-0362d507296e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7436461fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, acc_5 = model_5.evaluate(X_test_norm, y_test, verbose = 0)\n",
        "acc_5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRwSnM2SRnY0",
        "outputId": "e9f2b7f6-1644-409c-aaa4-d0a795220620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8568999767303467"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.save('model_5.h5')"
      ],
      "metadata": {
        "id": "smCawRH6R_Km"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}